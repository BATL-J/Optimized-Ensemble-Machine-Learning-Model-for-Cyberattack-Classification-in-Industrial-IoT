{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab31976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading Dataset and Pre-processing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ydata_profiling import ProfileReport\n",
    "import missingno as msno\n",
    "from warnings import simplefilter\n",
    "\n",
    "#ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.datasets import make_moons\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import mode\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "#ploting\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed430e",
   "metadata": {},
   "source": [
    "# 1.Component Contribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3dd58",
   "metadata": {},
   "source": [
    "# Case 1 : Base model \n",
    "- No SMOTE\n",
    "- No Feature Engineering\n",
    "- No hyperparameter Tuning\n",
    "- No Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d27a98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.transmit_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157795</th>\n",
       "      <td>2021 23:24:32.698981000</td>\n",
       "      <td>193.152.82.43</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>48729.0</td>\n",
       "      <td>40690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157796</th>\n",
       "      <td>2021 23:24:32.699354000</td>\n",
       "      <td>253.52.1.213</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45657.0</td>\n",
       "      <td>40702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157797</th>\n",
       "      <td>2021 23:24:32.719931000</td>\n",
       "      <td>107.155.221.49</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57686.0</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157798</th>\n",
       "      <td>2021 23:24:32.752054000</td>\n",
       "      <td>77.242.58.228</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9555.0</td>\n",
       "      <td>42379.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157799</th>\n",
       "      <td>2021 23:24:32.780376000</td>\n",
       "      <td>149.40.90.151</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35144.0</td>\n",
       "      <td>45095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157800 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       frame.time     ip.src_host    ip.dst_host  \\\n",
       "0                             6.0   192.168.0.152            0.0   \n",
       "1                             6.0   192.168.0.101            0.0   \n",
       "2                             6.0   192.168.0.152            0.0   \n",
       "3                             6.0   192.168.0.101            0.0   \n",
       "4                             6.0   192.168.0.152            0.0   \n",
       "...                           ...             ...            ...   \n",
       "157795   2021 23:24:32.698981000    193.152.82.43  192.168.0.128   \n",
       "157796   2021 23:24:32.699354000     253.52.1.213  192.168.0.128   \n",
       "157797   2021 23:24:32.719931000   107.155.221.49  192.168.0.128   \n",
       "157798   2021 23:24:32.752054000    77.242.58.228  192.168.0.128   \n",
       "157799   2021 23:24:32.780376000    149.40.90.151  192.168.0.128   \n",
       "\n",
       "       arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
       "0                     0.0         0.0          0.0                0.0   \n",
       "1                     0.0         0.0          0.0                0.0   \n",
       "2                     0.0         0.0          0.0                0.0   \n",
       "3                     0.0         0.0          0.0                0.0   \n",
       "4                     0.0         0.0          0.0                0.0   \n",
       "...                   ...         ...          ...                ...   \n",
       "157795                  0         0.0          0.0                  0   \n",
       "157796                  0         0.0          0.0                  0   \n",
       "157797                  0         0.0          0.0                  0   \n",
       "157798                  0         0.0          0.0                  0   \n",
       "157799                  0         0.0          0.0                  0   \n",
       "\n",
       "        icmp.checksum  icmp.seq_le  icmp.transmit_timestamp  ...  \\\n",
       "0                 0.0          0.0                      0.0  ...   \n",
       "1                 0.0          0.0                      0.0  ...   \n",
       "2                 0.0          0.0                      0.0  ...   \n",
       "3                 0.0          0.0                      0.0  ...   \n",
       "4                 0.0          0.0                      0.0  ...   \n",
       "...               ...          ...                      ...  ...   \n",
       "157795        48729.0      40690.0                      0.0  ...   \n",
       "157796        45657.0      40702.0                      0.0  ...   \n",
       "157797        57686.0      41423.0                      0.0  ...   \n",
       "157798         9555.0      42379.0                      0.0  ...   \n",
       "157799        35144.0      45095.0                      0.0  ...   \n",
       "\n",
       "        mqtt.proto_len mqtt.protoname  mqtt.topic mqtt.topic_len mqtt.ver  \\\n",
       "0                  0.0            0.0         0.0            0.0      0.0   \n",
       "1                  0.0            0.0         0.0            0.0      0.0   \n",
       "2                  0.0            0.0         0.0            0.0      0.0   \n",
       "3                  0.0            0.0         0.0            0.0      0.0   \n",
       "4                  0.0            0.0         0.0            0.0      0.0   \n",
       "...                ...            ...         ...            ...      ...   \n",
       "157795             0.0            0.0         0.0            0.0      0.0   \n",
       "157796             0.0            0.0         0.0            0.0      0.0   \n",
       "157797             0.0            0.0         0.0            0.0      0.0   \n",
       "157798             0.0            0.0         0.0            0.0      0.0   \n",
       "157799             0.0            0.0         0.0            0.0      0.0   \n",
       "\n",
       "       mbtcp.len mbtcp.trans_id mbtcp.unit_id  Attack_label  Attack_type  \n",
       "0            0.0            0.0           0.0             1         MITM  \n",
       "1            0.0            0.0           0.0             1         MITM  \n",
       "2            0.0            0.0           0.0             1         MITM  \n",
       "3            0.0            0.0           0.0             1         MITM  \n",
       "4            0.0            0.0           0.0             1         MITM  \n",
       "...          ...            ...           ...           ...          ...  \n",
       "157795       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157796       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157797       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157798       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157799       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "\n",
       "[157800 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Case1 = pd.read_csv(\"ML-EdgeIIoT-dataset.csv\", low_memory=False) \n",
    "df_Case1 # pandas.errors.DtypeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4793a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "Normal                   24101\n",
      "DDoS_UDP                 14498\n",
      "DDoS_ICMP                13096\n",
      "DDoS_HTTP                10495\n",
      "SQL_injection            10282\n",
      "DDoS_TCP                 10247\n",
      "Uploading                10214\n",
      "Vulnerability_scanner    10062\n",
      "Password                  9972\n",
      "Backdoor                  9865\n",
      "Ransomware                9689\n",
      "XSS                       9543\n",
      "Port_Scanning             8921\n",
      "Fingerprinting             853\n",
      "MITM                       358\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['frame.time','http.file_data',\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "                \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "                \"tcp.dstport\", \"udp.port\", \"mqtt.msg\", \"icmp.unused\", \"http.tls_port\",\n",
    "                'dns.qry.type', 'dns.retransmit_request_in', \"mqtt.msg_decoded_as\",\n",
    "                \"mbtcp.trans_id\", \"mbtcp.unit_id\" , \"ip.src_host\" , \"ip.dst_host\" ,\n",
    "                \"arp.dst.proto_ipv4\" , \"arp.src.proto_ipv4\" , 'http.request.method' ,\n",
    "                'http.request.method', 'http.referer' , \"http.request.version\" ,\n",
    "                \"dns.qry.name.len\" , \"mqtt.conack.flags\" , \"mqtt.protoname\" , \"mqtt.topic\"]\n",
    "\n",
    "df_Case1.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "df_Case1.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df_Case1.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "df_Case1 = shuffle(df_Case1)\n",
    "\n",
    "df_Case1.isna().sum()\n",
    "\n",
    "print(df_Case1['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81bf4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 152196\n",
      "Number of columns: 34\n",
      "Index(['arp.opcode', 'arp.hw.size', 'icmp.checksum', 'icmp.seq_le',\n",
      "       'http.content_length', 'http.response', 'tcp.ack', 'tcp.ack_raw',\n",
      "       'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst',\n",
      "       'tcp.connection.syn', 'tcp.connection.synack', 'tcp.flags',\n",
      "       'tcp.flags.ack', 'tcp.len', 'tcp.seq', 'udp.stream', 'udp.time_delta',\n",
      "       'dns.qry.name', 'dns.qry.qu', 'dns.retransmission',\n",
      "       'dns.retransmit_request', 'mqtt.conflag.cleansess', 'mqtt.conflags',\n",
      "       'mqtt.hdrflags', 'mqtt.len', 'mqtt.msgtype', 'mqtt.proto_len',\n",
      "       'mqtt.topic_len', 'mqtt.ver', 'mbtcp.len', 'Attack_label',\n",
      "       'Attack_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# number of rows in the dataset.\n",
    "print(f\"Number of rows: {df_Case1.shape[0]}\")\n",
    "\n",
    "# number of columns in the dataset.\n",
    "print(f\"Number of columns: {df_Case1.shape[1]}\")  \n",
    "\n",
    "# Check the names of the columns \n",
    "print(df_Case1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95b89ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "7     24101\n",
       "4     14498\n",
       "2     13096\n",
       "1     10495\n",
       "11    10282\n",
       "3     10247\n",
       "12    10214\n",
       "13    10062\n",
       "8      9972\n",
       "0      9865\n",
       "10     9689\n",
       "14     9543\n",
       "9      8921\n",
       "5       853\n",
       "6       358\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_Case1['Attack_type'] = label_encoder.fit_transform(df_Case1['Attack_type'])\n",
    "df_Case1['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95185469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121756, 33)\n",
      "(30440, 33)\n",
      "(121756,)\n",
      "(30440,)\n"
     ]
    }
   ],
   "source": [
    "Y = df_Case1[\"Attack_type\"]\n",
    "X = df_Case1.drop('Attack_type', axis=1) # after filtring feat\n",
    "\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2,random_state=111)\n",
    "print(train_X.shape),\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf088e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "7     19336\n",
      "4     11633\n",
      "2     10450\n",
      "1      8367\n",
      "3      8218\n",
      "12     8211\n",
      "11     8210\n",
      "13     8014\n",
      "8      7940\n",
      "0      7853\n",
      "14     7647\n",
      "10     7647\n",
      "9      7241\n",
      "5       692\n",
      "6       297\n",
      "Name: count, dtype: int64\n",
      "------------------------------------\n",
      "Attack_type\n",
      "7     19336\n",
      "4     11633\n",
      "2     10450\n",
      "1      8367\n",
      "3      8218\n",
      "12     8211\n",
      "11     8210\n",
      "13     8014\n",
      "8      7940\n",
      "0      7853\n",
      "14     7647\n",
      "10     7647\n",
      "9      7241\n",
      "5       692\n",
      "6       297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.value_counts())\n",
    "print('------------------------------------')\n",
    "print(train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920bbb1",
   "metadata": {},
   "source": [
    "## 1.1 Testing Models for Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b65ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store training and testing times\n",
    "results = {\"Model\": [], \"Training Time (s)\": [], \"Testing Time (s)\": [] , \"AUROC\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b42ec2",
   "metadata": {},
   "source": [
    "### 1.1.1 DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a0376fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8902759526938239\n",
      "AUROC: 0.9326808267639103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DecisionTreeClassifier instance\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# ---------------------Measure training time---------------------\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "decision_tree.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred = decision_tree.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"DT\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y, y_pred)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "\n",
    "# ------------------ AUROC Calculation --------------------------\n",
    "# Calculate AUROC for multi-class classification using 'ovr' (One-vs-Rest) strategy\n",
    "auroc = roc_auc_score(test_Y, decision_tree.predict_proba(test_X), multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Optionally, store AUROC\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])  # Ensure key exists\n",
    "results[\"AUROC\"].append(auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c03a06df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1998\n",
      "           1       0.72      0.73      0.72      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.64      0.72      0.68       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.78      0.78      0.78      2002\n",
      "           9       0.88      0.86      0.87      1850\n",
      "          10       0.88      0.89      0.88      1952\n",
      "          11       0.75      0.75      0.75      2014\n",
      "          12       0.67      0.65      0.66      2094\n",
      "          13       0.95      0.96      0.96      2000\n",
      "          14       0.80      0.81      0.80      1911\n",
      "\n",
      "    accuracy                           0.89     30440\n",
      "   macro avg       0.87      0.87      0.87     30440\n",
      "weighted avg       0.89      0.89      0.89     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45c6fc",
   "metadata": {},
   "source": [
    "### 1.1.2 RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "69bacd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8978318002628121\n",
      "AUROC: 0.9750678123291474\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RFC_Model = RandomForestClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "RFC_Model.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_RFC = RFC_Model.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"RFC\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y, y_pred_GS_RFC)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    " \n",
    "# ------------------ AUROC Calculation --------------------------\n",
    "# Calculate AUROC for multi-class classification using 'ovr' (One-vs-Rest) strategy\n",
    "y_probs = RFC_Model.predict_proba(test_X)\n",
    "auroc = roc_auc_score(test_Y, y_probs, multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Optionally, store AUROC\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])  # Ensure key exists\n",
    "results[\"AUROC\"].append(auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5725b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1998\n",
      "           1       0.74      0.74      0.74      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.79      0.72      0.75       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.77      0.78      0.77      2002\n",
      "           9       0.87      0.98      0.92      1850\n",
      "          10       0.92      0.89      0.90      1952\n",
      "          11       0.74      0.75      0.75      2014\n",
      "          12       0.71      0.66      0.68      2094\n",
      "          13       0.98      0.96      0.97      2000\n",
      "          14       0.80      0.80      0.80      1911\n",
      "\n",
      "    accuracy                           0.90     30440\n",
      "   macro avg       0.88      0.88      0.88     30440\n",
      "weighted avg       0.90      0.90      0.90     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_GS_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e520ec",
   "metadata": {},
   "source": [
    "### 1.1.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dfa45469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.793709\n",
      "Accuracy: 0.339323258869908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression Model \n",
    "LR_Model = LogisticRegression(solver='liblinear', multi_class='ovr')  # OvR by default, or 'multinomial' for softmax\n",
    "\n",
    "# --------------------- Measure training time ---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "LR_Model.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_LR = LR_Model.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"Logistic Regression\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_LR = LR_Model.predict_proba(test_X)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "auroc = roc_auc_score(test_Y, y_proba_LR, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y, y_pred_GS_LR)\n",
    "print(\"Accuracy:\", accuracy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d1313d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1998\n",
      "           1       0.09      0.09      0.09      2107\n",
      "           2       0.95      1.00      0.98      2586\n",
      "           3       0.50      0.61      0.55      2043\n",
      "           4       0.52      1.00      0.69      2868\n",
      "           5       0.00      0.00      0.00       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       0.21      0.62      0.32      4786\n",
      "           8       0.00      0.00      0.00      2002\n",
      "           9       0.00      0.00      0.00      1850\n",
      "          10       0.00      0.00      0.00      1952\n",
      "          11       0.12      0.20      0.15      2014\n",
      "          12       0.00      0.00      0.00      2094\n",
      "          13       0.00      0.00      0.00      2000\n",
      "          14       0.00      0.00      0.00      1911\n",
      "\n",
      "    accuracy                           0.34     30440\n",
      "   macro avg       0.23      0.30      0.25     30440\n",
      "weighted avg       0.21      0.34      0.25     30440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_GS_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea675b",
   "metadata": {},
   "source": [
    "### 1.1.4 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55797c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9901770754624002\n",
      "Test Accuracy: 0.896550591327201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  base model\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "#  bagging model\n",
    "bagging_model = BaggingClassifier(estimator=base_model)\n",
    "\n",
    "# bagging model\n",
    "bagging_model.fit(train_X, train_Y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = bagging_model.predict(test_X)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Training Accuracy:\", bagging_model.score(train_X, train_Y))\n",
    "print(\"Test Accuracy:\", bagging_model.score(test_X, test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc08160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1998\n",
      "           1       0.73      0.74      0.73      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.78      0.72      0.75       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.76      0.79      0.77      2002\n",
      "           9       0.87      0.96      0.91      1850\n",
      "          10       0.91      0.88      0.90      1952\n",
      "          11       0.74      0.75      0.75      2014\n",
      "          12       0.71      0.65      0.68      2094\n",
      "          13       0.98      0.96      0.97      2000\n",
      "          14       0.81      0.81      0.81      1911\n",
      "\n",
      "    accuracy                           0.90     30440\n",
      "   macro avg       0.88      0.88      0.88     30440\n",
      "weighted avg       0.90      0.90      0.90     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e0fbd",
   "metadata": {},
   "source": [
    "### 1.1.5 Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "53ebec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9621992577059211\n",
      "Train\n",
      "0.9975442688656001\n",
      "Test\n",
      "0.8834099868593955\n"
     ]
    }
   ],
   "source": [
    "ex_tree_clf = ExtraTreesClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "ex_tree_clf.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# ------------------ AUROC ------------------\n",
    "# Predict probabilities instead of labels\n",
    "proba = ex_tree_clf.predict_proba(test_X)\n",
    "\n",
    "# Get number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "\n",
    "# AUROC calculation\n",
    "auroc = roc_auc_score(test_Y, proba, multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# ------------------ Store Results ------------------\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "print (\"Train\")\n",
    "print(accuracy_score(train_Y, ex_tree_clf.predict(train_X)) )\n",
    "print (\"Test\")\n",
    "print( accuracy_score(test_Y.values, ex_tree_clf.predict(test_X)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      1998\n",
      "           1       0.70      0.69      0.69      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.75      0.72      0.74       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.74      0.75      0.75      2002\n",
      "           9       0.87      0.96      0.91      1850\n",
      "          10       0.92      0.89      0.90      1952\n",
      "          11       0.69      0.73      0.71      2014\n",
      "          12       0.67      0.64      0.66      2094\n",
      "          13       0.97      0.91      0.94      2000\n",
      "          14       0.77      0.77      0.77      1911\n",
      "\n",
      "    accuracy                           0.88     30440\n",
      "   macro avg       0.87      0.87      0.87     30440\n",
      "weighted avg       0.88      0.88      0.88     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_extraTree = ex_tree_clf.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"ExtraTreesClassifier\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_extraTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cbd6a",
   "metadata": {},
   "source": [
    "### 1.1.6 AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9566\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1998\n",
      "           1       0.72      0.72      0.72      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.65      0.72      0.68       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.78      0.78      0.78      2002\n",
      "           9       0.88      0.87      0.87      1850\n",
      "          10       0.89      0.89      0.89      1952\n",
      "          11       0.75      0.75      0.75      2014\n",
      "          12       0.67      0.66      0.66      2094\n",
      "          13       0.95      0.96      0.96      2000\n",
      "          14       0.79      0.81      0.80      1911\n",
      "\n",
      "    accuracy                           0.89     30440\n",
      "   macro avg       0.87      0.87      0.87     30440\n",
      "weighted avg       0.89      0.89      0.89     30440\n",
      "\n",
      "Accuracy: 0.8900\n",
      "Training Time: 31.2130 seconds\n",
      "Testing Time: 0.3777 seconds\n",
      "Final Model Score: 0.8900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base classifier \n",
    "base_estimator = DecisionTreeClassifier()  \n",
    "\n",
    "ada_boost = AdaBoostClassifier(estimator=base_estimator)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "ada_boost.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# --------------------- Measure testing time ---------------------\n",
    "start_time = time.time()\n",
    "y_pred_aba = ada_boost.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# --------------------- Evaluate Model ---------------------\n",
    "# Calculate accuracy and other classification metrics\n",
    "accuracy = accuracy_score(test_Y, y_pred_aba)\n",
    "class_report = classification_report(test_Y, y_pred_aba)\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"AdaBoost\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "# --------------------- AUROC Calculation ---------------------\n",
    "# Predict probabilities for AUROC\n",
    "y_proba_aba = ada_boost.predict_proba(test_X)\n",
    "\n",
    "# Determine number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "\n",
    "# Compute AUROC using One-vs-Rest strategy for multiclass\n",
    "auroc = roc_auc_score(test_Y, y_proba_aba, multi_class='ovr')\n",
    "\n",
    "# Print AUROC\n",
    "print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "# Store AUROC in results\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "\n",
    "# Optionally print classification report\n",
    "print(f\"Classification Report for AdaBoost:\\n{class_report}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "print(f\"Testing Time: {testing_time:.4f} seconds\")\n",
    "\n",
    "# --------------------- Final Score ---------------------\n",
    "final_score = ada_boost.score(test_X, test_Y)\n",
    "print(f\"Final Model Score: {final_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c556a",
   "metadata": {},
   "source": [
    "### 1.1.7 XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "689a4ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.993888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9058804204993429"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_boost=xgb.XGBClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "xgb_boost.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_xgb = xgb_boost.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"XGBoost\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_xgb = xgb_boost.predict_proba(test_X)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "auroc = roc_auc_score(test_Y, y_proba_xgb, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "xgb_boost.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95950e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      1998\n",
      "           1       0.61      0.89      0.72      2107\n",
      "           2       1.00      1.00      1.00      2586\n",
      "           3       1.00      1.00      1.00      2043\n",
      "           4       1.00      1.00      1.00      2868\n",
      "           5       0.88      0.69      0.77       164\n",
      "           6       1.00      1.00      1.00        65\n",
      "           7       1.00      1.00      1.00      4786\n",
      "           8       0.79      0.78      0.79      2002\n",
      "           9       0.86      1.00      0.93      1850\n",
      "          10       0.99      0.88      0.93      1952\n",
      "          11       0.76      0.77      0.76      2014\n",
      "          12       0.86      0.61      0.72      2094\n",
      "          13       0.99      0.96      0.98      2000\n",
      "          14       0.88      0.79      0.83      1911\n",
      "\n",
      "    accuracy                           0.91     30440\n",
      "   macro avg       0.91      0.89      0.89     30440\n",
      "weighted avg       0.92      0.91      0.91     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9beedc7",
   "metadata": {},
   "source": [
    "### 1.1.7 LGBM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dd280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2421\n",
      "[LightGBM] [Info] Number of data points in the train set: 121756, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -2.739342\n",
      "[LightGBM] [Info] Start training from score -2.675217\n",
      "[LightGBM] [Info] Start training from score -2.449692\n",
      "[LightGBM] [Info] Start training from score -2.697397\n",
      "[LightGBM] [Info] Start training from score -2.348431\n",
      "[LightGBM] [Info] Start training from score -5.174533\n",
      "[LightGBM] [Info] Start training from score -6.029602\n",
      "[LightGBM] [Info] Start training from score -1.841137\n",
      "[LightGBM] [Info] Start training from score -2.726335\n",
      "[LightGBM] [Info] Start training from score -2.846017\n",
      "[LightGBM] [Info] Start training from score -2.756005\n",
      "[LightGBM] [Info] Start training from score -2.689626\n",
      "[LightGBM] [Info] Start training from score -2.707689\n",
      "[LightGBM] [Info] Start training from score -2.714857\n",
      "[LightGBM] [Info] Start training from score -2.769669\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "AUROC: 0.496671\n",
      "Accuracy: 0.06491458607095926\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1998\n",
      "           1       0.13      0.01      0.01      2107\n",
      "           2       0.00      0.00      0.00      2586\n",
      "           3       0.00      0.00      0.00      2043\n",
      "           4       0.00      0.00      0.00      2868\n",
      "           5       0.00      0.00      0.00       164\n",
      "           6       0.00      0.00      0.00        65\n",
      "           7       0.98      0.05      0.10      4786\n",
      "           8       0.04      0.24      0.07      2002\n",
      "           9       0.00      0.00      0.00      1850\n",
      "          10       0.99      0.08      0.15      1952\n",
      "          11       1.00      0.00      0.00      2014\n",
      "          12       0.31      0.03      0.05      2094\n",
      "          13       0.45      0.50      0.47      2000\n",
      "          14       0.22      0.01      0.03      1911\n",
      "\n",
      "    accuracy                           0.06     30440\n",
      "   macro avg       0.27      0.06      0.06     30440\n",
      "weighted avg       0.36      0.06      0.07     30440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# a new instance of the LGBMClassifier \n",
    "LGBM_Model_best = LGBMClassifier()\n",
    "\n",
    "# --------------------- Measure training time ---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "LGBM_Model_best.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_LGBM = LGBM_Model_best.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"LGBMClassifier\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_LGBM = LGBM_Model_best.predict_proba(test_X)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "auroc = roc_auc_score(test_Y, y_proba_LGBM, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y, y_pred_GS_LGBM)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "\n",
    "# evaluation for multi-class classification\n",
    "print(\"Classification Report:\\n\", classification_report(test_Y, y_pred_GS_LGBM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eea9ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1998\n",
      "           1       0.13      0.01      0.01      2107\n",
      "           2       0.00      0.00      0.00      2586\n",
      "           3       0.00      0.00      0.00      2043\n",
      "           4       0.00      0.00      0.00      2868\n",
      "           5       0.00      0.00      0.00       164\n",
      "           6       0.00      0.00      0.00        65\n",
      "           7       0.98      0.05      0.10      4786\n",
      "           8       0.04      0.24      0.07      2002\n",
      "           9       0.00      0.00      0.00      1850\n",
      "          10       0.99      0.08      0.15      1952\n",
      "          11       1.00      0.00      0.00      2014\n",
      "          12       0.31      0.03      0.05      2094\n",
      "          13       0.45      0.50      0.47      2000\n",
      "          14       0.22      0.01      0.03      1911\n",
      "\n",
      "    accuracy                           0.06     30440\n",
      "   macro avg       0.27      0.06      0.06     30440\n",
      "weighted avg       0.36      0.06      0.07     30440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_GS_LGBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e34a4",
   "metadata": {},
   "source": [
    "### 1.1.8 Stack_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6685170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.991859\n",
      "Accuracy: 90.58 %\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "ada_boost = AdaBoostClassifier()\n",
    "xgb_boost=xgb.XGBClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#  stacking ensemble\n",
    "stack = StackingClassifier( estimators=[\n",
    "                                        ('ada', ada_boost),\n",
    "                                        ('xgb', xgb_boost)],\n",
    "                                        final_estimator= random_forest\n",
    "                                      )\n",
    "\n",
    "\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit ensemble on data\n",
    "stack.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Make predictions\n",
    "y_pred = stack.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"Stacked Ensemble_1\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_stack_1 = stack.predict_proba(test_X)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y))\n",
    "auroc = roc_auc_score(test_Y, y_proba_stack_1, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "\n",
    "# Evaluate performance\n",
    "acc = accuracy_score(test_Y, y_pred)\n",
    "acc = acc*100\n",
    "print(f'Accuracy: {acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609faa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      2012\n",
      "           1       0.59      0.90      0.71      2128\n",
      "           2       1.00      1.00      1.00      2646\n",
      "           3       1.00      1.00      1.00      2029\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.97      0.63      0.77       161\n",
      "           6       1.00      1.00      1.00        61\n",
      "           7       1.00      1.00      1.00      4765\n",
      "           8       0.79      0.80      0.79      2032\n",
      "           9       0.86      1.00      0.93      1680\n",
      "          10       1.00      0.88      0.94      2042\n",
      "          11       0.78      0.75      0.76      2072\n",
      "          12       0.90      0.63      0.74      2003\n",
      "          13       0.99      0.95      0.97      2048\n",
      "          14       0.87      0.79      0.83      1896\n",
      "\n",
      "    accuracy                           0.91     30440\n",
      "   macro avg       0.92      0.88      0.89     30440\n",
      "weighted avg       0.92      0.91      0.91     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack1 = stack.predict(test_X)\n",
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_stack1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c496564",
   "metadata": {},
   "source": [
    "### 1.1.9 Stack_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfda67ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2421\n",
      "[LightGBM] [Info] Number of data points in the train set: 121756, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -2.741123\n",
      "[LightGBM] [Info] Start training from score -2.677724\n",
      "[LightGBM] [Info] Start training from score -2.455417\n",
      "[LightGBM] [Info] Start training from score -2.695692\n",
      "[LightGBM] [Info] Start training from score -2.348173\n",
      "[LightGBM] [Info] Start training from score -5.170188\n",
      "[LightGBM] [Info] Start training from score -6.016042\n",
      "[LightGBM] [Info] Start training from score -1.840050\n",
      "[LightGBM] [Info] Start training from score -2.730106\n",
      "[LightGBM] [Info] Start training from score -2.822260\n",
      "[LightGBM] [Info] Start training from score -2.767706\n",
      "[LightGBM] [Info] Start training from score -2.696666\n",
      "[LightGBM] [Info] Start training from score -2.696544\n",
      "[LightGBM] [Info] Start training from score -2.720829\n",
      "[LightGBM] [Info] Start training from score -2.767706\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2410\n",
      "[LightGBM] [Info] Number of data points in the train set: 97404, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -2.741179\n",
      "[LightGBM] [Info] Start training from score -2.677656\n",
      "[LightGBM] [Info] Start training from score -2.455409\n",
      "[LightGBM] [Info] Start training from score -2.695593\n",
      "[LightGBM] [Info] Start training from score -2.348208\n",
      "[LightGBM] [Info] Start training from score -5.169458\n",
      "[LightGBM] [Info] Start training from score -6.018562\n",
      "[LightGBM] [Info] Start training from score -1.840094\n",
      "[LightGBM] [Info] Start training from score -2.730098\n",
      "[LightGBM] [Info] Start training from score -2.822217\n",
      "[LightGBM] [Info] Start training from score -2.767795\n",
      "[LightGBM] [Info] Start training from score -2.696658\n",
      "[LightGBM] [Info] Start training from score -2.696506\n",
      "[LightGBM] [Info] Start training from score -2.720696\n",
      "[LightGBM] [Info] Start training from score -2.767795\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 97405, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -2.741189\n",
      "[LightGBM] [Info] Start training from score -2.677666\n",
      "[LightGBM] [Info] Start training from score -2.455419\n",
      "[LightGBM] [Info] Start training from score -2.695603\n",
      "[LightGBM] [Info] Start training from score -2.348218\n",
      "[LightGBM] [Info] Start training from score -5.169468\n",
      "[LightGBM] [Info] Start training from score -6.014362\n",
      "[LightGBM] [Info] Start training from score -1.840040\n",
      "[LightGBM] [Info] Start training from score -2.730108\n",
      "[LightGBM] [Info] Start training from score -2.822227\n",
      "[LightGBM] [Info] Start training from score -2.767806\n",
      "[LightGBM] [Info] Start training from score -2.696668\n",
      "[LightGBM] [Info] Start training from score -2.696516\n",
      "[LightGBM] [Info] Start training from score -2.720862\n",
      "[LightGBM] [Info] Start training from score -2.767806\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 97405, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -2.741030\n",
      "[LightGBM] [Info] Start training from score -2.677815\n",
      "[LightGBM] [Info] Start training from score -2.455419\n",
      "[LightGBM] [Info] Start training from score -2.695755\n",
      "[LightGBM] [Info] Start training from score -2.348218\n",
      "[LightGBM] [Info] Start training from score -5.171275\n",
      "[LightGBM] [Info] Start training from score -6.014362\n",
      "[LightGBM] [Info] Start training from score -1.840040\n",
      "[LightGBM] [Info] Start training from score -2.730108\n",
      "[LightGBM] [Info] Start training from score -2.822227\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Info] Start training from score -2.696668\n",
      "[LightGBM] [Info] Start training from score -2.696516\n",
      "[LightGBM] [Info] Start training from score -2.720862\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 97405, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -2.741030\n",
      "[LightGBM] [Info] Start training from score -2.677815\n",
      "[LightGBM] [Info] Start training from score -2.455419\n",
      "[LightGBM] [Info] Start training from score -2.695755\n",
      "[LightGBM] [Info] Start training from score -2.348111\n",
      "[LightGBM] [Info] Start training from score -5.171275\n",
      "[LightGBM] [Info] Start training from score -6.014362\n",
      "[LightGBM] [Info] Start training from score -1.840040\n",
      "[LightGBM] [Info] Start training from score -2.730108\n",
      "[LightGBM] [Info] Start training from score -2.822227\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Info] Start training from score -2.696668\n",
      "[LightGBM] [Info] Start training from score -2.696668\n",
      "[LightGBM] [Info] Start training from score -2.720862\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2409\n",
      "[LightGBM] [Info] Number of data points in the train set: 97405, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -2.741189\n",
      "[LightGBM] [Info] Start training from score -2.677666\n",
      "[LightGBM] [Info] Start training from score -2.455419\n",
      "[LightGBM] [Info] Start training from score -2.695755\n",
      "[LightGBM] [Info] Start training from score -2.348111\n",
      "[LightGBM] [Info] Start training from score -5.169468\n",
      "[LightGBM] [Info] Start training from score -6.018573\n",
      "[LightGBM] [Info] Start training from score -1.840040\n",
      "[LightGBM] [Info] Start training from score -2.730108\n",
      "[LightGBM] [Info] Start training from score -2.822400\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Info] Start training from score -2.696668\n",
      "[LightGBM] [Info] Start training from score -2.696516\n",
      "[LightGBM] [Info] Start training from score -2.720862\n",
      "[LightGBM] [Info] Start training from score -2.767642\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Accuracy: 90.67 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# base models\n",
    "logistic_reg = LogisticRegression()\n",
    "xgb_boost = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "extra_trees = ExtraTreesClassifier()\n",
    "\n",
    "# the final estimator\n",
    "final_estimator = RandomForestClassifier()\n",
    "\n",
    "# Create a stacking ensemble with a mix of models\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', logistic_reg),\n",
    "        ('xgb', xgb_boost),\n",
    "        ('lgbm', lgbm),\n",
    "        ('extra', extra_trees)\n",
    "    ],\n",
    "    final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit ensemble on data\n",
    "stack.fit(train_X, train_Y)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Make predictions\n",
    "y_pred = stack.predict(test_X)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results[\"Model\"].append(\"Stacked Ensemble_1\")\n",
    "results[\"Training Time (s)\"].append(training_time)\n",
    "results[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# Measure accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_Y, y_pred)\n",
    "print(f'Accuracy: {acc * 100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c268436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      2012\n",
      "           1       0.61      0.89      0.72      2128\n",
      "           2       1.00      1.00      1.00      2646\n",
      "           3       1.00      1.00      1.00      2029\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.99      0.65      0.79       161\n",
      "           6       1.00      1.00      1.00        61\n",
      "           7       1.00      1.00      1.00      4765\n",
      "           8       0.76      0.81      0.79      2032\n",
      "           9       0.86      1.00      0.93      1680\n",
      "          10       1.00      0.88      0.94      2042\n",
      "          11       0.79      0.74      0.77      2072\n",
      "          12       0.83      0.64      0.73      2003\n",
      "          13       1.00      0.95      0.97      2048\n",
      "          14       0.90      0.78      0.84      1896\n",
      "\n",
      "    accuracy                           0.91     30440\n",
      "   macro avg       0.92      0.88      0.89     30440\n",
      "weighted avg       0.92      0.91      0.91     30440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack = stack.predict(test_X)\n",
    "print(\"Report :\\n\", classification_report(test_Y, y_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb20453",
   "metadata": {},
   "source": [
    "# Case 2 : Base model + Data pre-processing + Feature Engineering + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ebe0729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.transmit_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157795</th>\n",
       "      <td>2021 23:24:32.698981000</td>\n",
       "      <td>193.152.82.43</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>48729.0</td>\n",
       "      <td>40690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157796</th>\n",
       "      <td>2021 23:24:32.699354000</td>\n",
       "      <td>253.52.1.213</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45657.0</td>\n",
       "      <td>40702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157797</th>\n",
       "      <td>2021 23:24:32.719931000</td>\n",
       "      <td>107.155.221.49</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57686.0</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157798</th>\n",
       "      <td>2021 23:24:32.752054000</td>\n",
       "      <td>77.242.58.228</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9555.0</td>\n",
       "      <td>42379.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157799</th>\n",
       "      <td>2021 23:24:32.780376000</td>\n",
       "      <td>149.40.90.151</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35144.0</td>\n",
       "      <td>45095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157800 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       frame.time     ip.src_host    ip.dst_host  \\\n",
       "0                             6.0   192.168.0.152            0.0   \n",
       "1                             6.0   192.168.0.101            0.0   \n",
       "2                             6.0   192.168.0.152            0.0   \n",
       "3                             6.0   192.168.0.101            0.0   \n",
       "4                             6.0   192.168.0.152            0.0   \n",
       "...                           ...             ...            ...   \n",
       "157795   2021 23:24:32.698981000    193.152.82.43  192.168.0.128   \n",
       "157796   2021 23:24:32.699354000     253.52.1.213  192.168.0.128   \n",
       "157797   2021 23:24:32.719931000   107.155.221.49  192.168.0.128   \n",
       "157798   2021 23:24:32.752054000    77.242.58.228  192.168.0.128   \n",
       "157799   2021 23:24:32.780376000    149.40.90.151  192.168.0.128   \n",
       "\n",
       "       arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
       "0                     0.0         0.0          0.0                0.0   \n",
       "1                     0.0         0.0          0.0                0.0   \n",
       "2                     0.0         0.0          0.0                0.0   \n",
       "3                     0.0         0.0          0.0                0.0   \n",
       "4                     0.0         0.0          0.0                0.0   \n",
       "...                   ...         ...          ...                ...   \n",
       "157795                  0         0.0          0.0                  0   \n",
       "157796                  0         0.0          0.0                  0   \n",
       "157797                  0         0.0          0.0                  0   \n",
       "157798                  0         0.0          0.0                  0   \n",
       "157799                  0         0.0          0.0                  0   \n",
       "\n",
       "        icmp.checksum  icmp.seq_le  icmp.transmit_timestamp  ...  \\\n",
       "0                 0.0          0.0                      0.0  ...   \n",
       "1                 0.0          0.0                      0.0  ...   \n",
       "2                 0.0          0.0                      0.0  ...   \n",
       "3                 0.0          0.0                      0.0  ...   \n",
       "4                 0.0          0.0                      0.0  ...   \n",
       "...               ...          ...                      ...  ...   \n",
       "157795        48729.0      40690.0                      0.0  ...   \n",
       "157796        45657.0      40702.0                      0.0  ...   \n",
       "157797        57686.0      41423.0                      0.0  ...   \n",
       "157798         9555.0      42379.0                      0.0  ...   \n",
       "157799        35144.0      45095.0                      0.0  ...   \n",
       "\n",
       "        mqtt.proto_len mqtt.protoname  mqtt.topic mqtt.topic_len mqtt.ver  \\\n",
       "0                  0.0            0.0         0.0            0.0      0.0   \n",
       "1                  0.0            0.0         0.0            0.0      0.0   \n",
       "2                  0.0            0.0         0.0            0.0      0.0   \n",
       "3                  0.0            0.0         0.0            0.0      0.0   \n",
       "4                  0.0            0.0         0.0            0.0      0.0   \n",
       "...                ...            ...         ...            ...      ...   \n",
       "157795             0.0            0.0         0.0            0.0      0.0   \n",
       "157796             0.0            0.0         0.0            0.0      0.0   \n",
       "157797             0.0            0.0         0.0            0.0      0.0   \n",
       "157798             0.0            0.0         0.0            0.0      0.0   \n",
       "157799             0.0            0.0         0.0            0.0      0.0   \n",
       "\n",
       "       mbtcp.len mbtcp.trans_id mbtcp.unit_id  Attack_label  Attack_type  \n",
       "0            0.0            0.0           0.0             1         MITM  \n",
       "1            0.0            0.0           0.0             1         MITM  \n",
       "2            0.0            0.0           0.0             1         MITM  \n",
       "3            0.0            0.0           0.0             1         MITM  \n",
       "4            0.0            0.0           0.0             1         MITM  \n",
       "...          ...            ...           ...           ...          ...  \n",
       "157795       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157796       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157797       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157798       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157799       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "\n",
       "[157800 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Case2 = pd.read_csv(\"ML-EdgeIIoT-dataset.csv\", low_memory=False) \n",
    "df_Case2 # pandas.errors.DtypeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a54173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 157800\n",
      "Number of columns: 63\n",
      "Index(['frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4',\n",
      "       'arp.opcode', 'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum',\n",
      "       'icmp.seq_le', 'icmp.transmit_timestamp', 'icmp.unused',\n",
      "       'http.file_data', 'http.content_length', 'http.request.uri.query',\n",
      "       'http.request.method', 'http.referer', 'http.request.full_uri',\n",
      "       'http.request.version', 'http.response', 'http.tls_port', 'tcp.ack',\n",
      "       'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin',\n",
      "       'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack',\n",
      "       'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options',\n",
      "       'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream',\n",
      "       'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu',\n",
      "       'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request',\n",
      "       'dns.retransmit_request_in', 'mqtt.conack.flags',\n",
      "       'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len',\n",
      "       'mqtt.msg_decoded_as', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len',\n",
      "       'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver',\n",
      "       'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id', 'Attack_label',\n",
      "       'Attack_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    " # number of rows in the dataset.\n",
    "print(f\"Number of rows: {df_Case2.shape[0]}\")\n",
    "\n",
    "# number of columns in the dataset.\n",
    "print(f\"Number of columns: {df_Case2.shape[1]}\")  \n",
    "\n",
    "# Check the names of the columns \n",
    "print(df_Case2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7a329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame.time            0\n",
      "ip.src_host           0\n",
      "ip.dst_host           0\n",
      "arp.dst.proto_ipv4    0\n",
      "arp.opcode            0\n",
      "                     ..\n",
      "mbtcp.len             0\n",
      "mbtcp.trans_id        0\n",
      "mbtcp.unit_id         0\n",
      "Attack_label          0\n",
      "Attack_type           0\n",
      "Length: 63, dtype: int64\n",
      "----------------------------------------\n",
      "Before removing missing values (157800, 63)\n",
      "After removing missing values (157800, 63)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "copy1 = df_Case2.copy(deep=True)\n",
    "print(copy1.isnull().sum())\n",
    "\n",
    "# Drop rows that has missing values\n",
    "print('-'*40)\n",
    "copy2 = df_Case2.copy(deep=True)\n",
    "print('Before removing missing values', df_Case2.shape)\n",
    "copy2.dropna(inplace=True)\n",
    "print('After removing missing values',copy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43ced29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case2[\"tcp.srcport\"] = df_Case2[\"tcp.srcport\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b078bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.msgtype</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backdoor</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>...</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "      <td>10195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDoS_HTTP</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>...</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "      <td>10561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDoS_ICMP</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>...</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "      <td>14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDoS_TCP</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>...</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "      <td>10247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>...</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "      <td>14498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fingerprinting</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>...</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MITM</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>...</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>...</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "      <td>24301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Password</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>...</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "      <td>9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>...</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "      <td>10071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ransomware</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>...</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "      <td>10925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SQL_injection</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>...</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "      <td>10311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Uploading</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>...</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "      <td>10269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vulnerability_scanner</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>...</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "      <td>10076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XSS</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>...</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "      <td>10052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attack_type  frame.time  ip.src_host  ip.dst_host  \\\n",
       "0                Backdoor       10195        10195        10195   \n",
       "1               DDoS_HTTP       10561        10561        10561   \n",
       "2               DDoS_ICMP       14090        14090        14090   \n",
       "3                DDoS_TCP       10247        10247        10247   \n",
       "4                DDoS_UDP       14498        14498        14498   \n",
       "5          Fingerprinting        1001         1001         1001   \n",
       "6                    MITM        1214         1214         1214   \n",
       "7                  Normal       24301        24301        24301   \n",
       "8                Password        9989         9989         9989   \n",
       "9           Port_Scanning       10071        10071        10071   \n",
       "10             Ransomware       10925        10925        10925   \n",
       "11          SQL_injection       10311        10311        10311   \n",
       "12              Uploading       10269        10269        10269   \n",
       "13  Vulnerability_scanner       10076        10076        10076   \n",
       "14                    XSS       10052        10052        10052   \n",
       "\n",
       "    arp.dst.proto_ipv4  arp.opcode  arp.hw.size  arp.src.proto_ipv4  \\\n",
       "0                10195       10195        10195               10195   \n",
       "1                10561       10561        10561               10561   \n",
       "2                14090       14090        14090               14090   \n",
       "3                10247       10247        10247               10247   \n",
       "4                14498       14498        14498               14498   \n",
       "5                 1001        1001         1001                1001   \n",
       "6                 1214        1214         1214                1214   \n",
       "7                24301       24301        24301               24301   \n",
       "8                 9989        9989         9989                9989   \n",
       "9                10071       10071        10071               10071   \n",
       "10               10925       10925        10925               10925   \n",
       "11               10311       10311        10311               10311   \n",
       "12               10269       10269        10269               10269   \n",
       "13               10076       10076        10076               10076   \n",
       "14               10052       10052        10052               10052   \n",
       "\n",
       "    icmp.checksum  icmp.seq_le  ...  mqtt.msgtype  mqtt.proto_len  \\\n",
       "0           10195        10195  ...         10195           10195   \n",
       "1           10561        10561  ...         10561           10561   \n",
       "2           14090        14090  ...         14090           14090   \n",
       "3           10247        10247  ...         10247           10247   \n",
       "4           14498        14498  ...         14498           14498   \n",
       "5            1001         1001  ...          1001            1001   \n",
       "6            1214         1214  ...          1214            1214   \n",
       "7           24301        24301  ...         24301           24301   \n",
       "8            9989         9989  ...          9989            9989   \n",
       "9           10071        10071  ...         10071           10071   \n",
       "10          10925        10925  ...         10925           10925   \n",
       "11          10311        10311  ...         10311           10311   \n",
       "12          10269        10269  ...         10269           10269   \n",
       "13          10076        10076  ...         10076           10076   \n",
       "14          10052        10052  ...         10052           10052   \n",
       "\n",
       "    mqtt.protoname  mqtt.topic  mqtt.topic_len  mqtt.ver  mbtcp.len  \\\n",
       "0            10195       10195           10195     10195      10195   \n",
       "1            10561       10561           10561     10561      10561   \n",
       "2            14090       14090           14090     14090      14090   \n",
       "3            10247       10247           10247     10247      10247   \n",
       "4            14498       14498           14498     14498      14498   \n",
       "5             1001        1001            1001      1001       1001   \n",
       "6             1214        1214            1214      1214       1214   \n",
       "7            24301       24301           24301     24301      24301   \n",
       "8             9989        9989            9989      9989       9989   \n",
       "9            10071       10071           10071     10071      10071   \n",
       "10           10925       10925           10925     10925      10925   \n",
       "11           10311       10311           10311     10311      10311   \n",
       "12           10269       10269           10269     10269      10269   \n",
       "13           10076       10076           10076     10076      10076   \n",
       "14           10052       10052           10052     10052      10052   \n",
       "\n",
       "    mbtcp.trans_id  mbtcp.unit_id  Attack_label  \n",
       "0            10195          10195         10195  \n",
       "1            10561          10561         10561  \n",
       "2            14090          14090         14090  \n",
       "3            10247          10247         10247  \n",
       "4            14498          14498         14498  \n",
       "5             1001           1001          1001  \n",
       "6             1214           1214          1214  \n",
       "7            24301          24301         24301  \n",
       "8             9989           9989          9989  \n",
       "9            10071          10071         10071  \n",
       "10           10925          10925         10925  \n",
       "11           10311          10311         10311  \n",
       "12           10269          10269         10269  \n",
       "13           10076          10076         10076  \n",
       "14           10052          10052         10052  \n",
       "\n",
       "[15 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attack = df_Case2.groupby(\"Attack_type\").count().reset_index()\n",
    "Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238a5b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "Normal                   24301\n",
       "DDoS_UDP                 14498\n",
       "DDoS_ICMP                14090\n",
       "Ransomware               10925\n",
       "DDoS_HTTP                10561\n",
       "SQL_injection            10311\n",
       "Uploading                10269\n",
       "DDoS_TCP                 10247\n",
       "Backdoor                 10195\n",
       "Vulnerability_scanner    10076\n",
       "Port_Scanning            10071\n",
       "XSS                      10052\n",
       "Password                  9989\n",
       "MITM                      1214\n",
       "Fingerprinting            1001\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of target_class column\n",
    "df_Case2['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b212286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>quantile</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.998420e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60076.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.318491e+06</td>\n",
       "      <td>1309285.5</td>\n",
       "      <td>1309285.5</td>\n",
       "      <td>2898725.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attack_label          mean     median   quantile        max   min\n",
       "0             0  1.998420e+01        0.0        0.0    60076.0   0.0\n",
       "1             1  1.318491e+06  1309285.5  1309285.5  2898725.0  12.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df_Case2[df_Case2['Attack_type'].isin(['Normal', 'DDoS_UDP'])]\n",
    "selected_columns = filtered_df[['dns.qry.name', 'icmp.seq_le', 'udp.stream', 'Attack_label']]\n",
    "summary_stats = selected_columns.groupby('Attack_label')['udp.stream'].agg(['mean', 'median', 'quantile', 'max', 'min']).reset_index()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83232fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/vxy7ms4s6q73xjslwrxbp_fw0000gn/T/ipykernel_7668/457827715.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  copy1['frame.time'] = pd.to_datetime(copy1['frame.time'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214     2021-01-01 22:14:30.939803\n",
      "1215     2021-01-01 22:14:30.939896\n",
      "1216     2021-01-01 22:14:31.371846\n",
      "1217     2021-01-01 22:14:31.371927\n",
      "1218     2021-01-01 22:14:31.910480\n",
      "                    ...            \n",
      "157795   2021-01-01 23:24:32.698981\n",
      "157796   2021-01-01 23:24:32.699354\n",
      "157797   2021-01-01 23:24:32.719931\n",
      "157798   2021-01-01 23:24:32.752054\n",
      "157799   2021-01-01 23:24:32.780376\n",
      "Name: frame.time, Length: 142095, dtype: datetime64[ns]\n",
      "------------------------------------------------\n",
      "Before removing missing values (157800, 63)\n",
      "After removing missing values (142095, 63)\n"
     ]
    }
   ],
   "source": [
    "copy1 = df_Case2.copy(deep=True)\n",
    "\n",
    "# Drop rows with values of '6.0' or '0.0' in the 'frame.time' column\n",
    "copy1 = copy1[~copy1['frame.time'].isin([6.0, 0.0])]\n",
    "\n",
    "# Convert 'frame.time' column to datetime data type\n",
    "copy1['frame.time'] = pd.to_datetime(copy1['frame.time'], errors='coerce')\n",
    "copy1 = copy1.dropna(subset=['frame.time'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(copy1['frame.time'])\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('Before removing missing values', df_Case2.shape)\n",
    "print('After removing missing values',copy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34cb0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting IP add\n",
    "def ip_to_int(ip):\n",
    "    try:\n",
    "        return int(ipaddress.IPv4Address(ip))\n",
    "    except ipaddress.AddressValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281a618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  0\n",
      "1                  0\n",
      "2                  0\n",
      "3                  0\n",
      "4                  0\n",
      "             ...    \n",
      "157795    3232235648\n",
      "157796    3232235648\n",
      "157797    3232235648\n",
      "157798    3232235648\n",
      "157799    3232235648\n",
      "Name: ip.dst_host, Length: 157800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_Case2[\"ip.dst_host\"] = df_Case2[\"ip.dst_host\"].apply(ip_to_int)\n",
    "print(df_Case2[\"ip.dst_host\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3826c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case2[\"ip.dst_host\"] = df_Case2[\"ip.dst_host\"].apply(ip_to_int)\n",
    "df_Case2['ip.src_host'] = df_Case2['ip.src_host'].apply(ip_to_int)\n",
    "#Col arp.dst.proto_ipv4\n",
    "df_Case2['arp.dst.proto_ipv4'] = df_Case2['arp.dst.proto_ipv4'].apply(ip_to_int)\n",
    "#Col arp.src.proto_ipv4\n",
    "df_Case2['arp.src.proto_ipv4'] = df_Case2['arp.src.proto_ipv4'].apply(ip_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eac2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/vxy7ms4s6q73xjslwrxbp_fw0000gn/T/ipykernel_7668/2252793545.py:6: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "157795    0.0\n",
       "157796    0.0\n",
       "157797    0.0\n",
       "157798    0.0\n",
       "157799    0.0\n",
       "Name: http.file_data, Length: 157800, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract text content from HTML\n",
    "def extract_text(html):\n",
    "    if pd.isnull(html) or not isinstance(html, str):\n",
    "        return ''  # Return an empty string for missing or non-string values\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "# Remove HTML tags and extract text content\n",
    "df_Case2['text_content'] = df_Case2['http.file_data'].apply(extract_text)\n",
    "# Extract numerical features\n",
    "df_Case2['text_length'] = df_Case2['text_content'].apply(len)\n",
    "df_Case2['word_count'] = df_Case2['text_content'].apply(lambda x: len(x.split()))\n",
    "# Add more feature extraction steps as needed\n",
    "\n",
    "# Convert columns to numerical data type\n",
    "numerical_features = ['text_length', 'word_count']  # Add more feature names if needed\n",
    "df_Case2[numerical_features] = df_Case2[numerical_features].astype(float)\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = MinMaxScaler()\n",
    "df_Case2[numerical_features] = scaler.fit_transform(df_Case2[numerical_features])\n",
    "\n",
    "# Print the preprocessed col\n",
    "df_Case2['http.file_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd40e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "Normal                   24110\n",
      "DDoS_UDP                 14498\n",
      "DDoS_ICMP                14090\n",
      "DDoS_HTTP                10495\n",
      "SQL_injection            10285\n",
      "DDoS_TCP                 10247\n",
      "Uploading                10222\n",
      "Vulnerability_scanner    10064\n",
      "Password                  9974\n",
      "Backdoor                  9872\n",
      "Ransomware                9699\n",
      "XSS                       9552\n",
      "Port_Scanning             8933\n",
      "Fingerprinting             860\n",
      "MITM                       363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['frame.time','http.file_data',\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "                \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "                \"tcp.dstport\", \"udp.port\", \"mqtt.msg\", \"icmp.unused\", \"http.tls_port\",\n",
    "                'dns.qry.type', 'dns.retransmit_request_in', \"mqtt.msg_decoded_as\",\n",
    "                \"mbtcp.trans_id\", \"mbtcp.unit_id\", 'text_content']\n",
    "\n",
    "df_Case2.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "df_Case2.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df_Case2.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "df_Case2 = shuffle(df_Case2)\n",
    "\n",
    "df_Case2.isna().sum()\n",
    "\n",
    "print(df_Case2['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71b1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_dummy(df, name):\n",
    "\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "\n",
    "    for x in dummies.columns:\n",
    "\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "\n",
    "        df[dummy_name] = dummies[x]\n",
    "\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "encode_text_dummy(df_Case2,'http.request.method')\n",
    "encode_text_dummy(df_Case2,'http.referer')\n",
    "encode_text_dummy(df_Case2,\"http.request.version\")\n",
    "encode_text_dummy(df_Case2,\"dns.qry.name.len\")\n",
    "encode_text_dummy(df_Case2,\"mqtt.conack.flags\")\n",
    "encode_text_dummy(df_Case2,\"mqtt.protoname\")\n",
    "encode_text_dummy(df_Case2,\"mqtt.topic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5f750e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "7     24110\n",
       "4     14498\n",
       "2     14090\n",
       "1     10495\n",
       "11    10285\n",
       "3     10247\n",
       "12    10222\n",
       "13    10064\n",
       "8      9974\n",
       "0      9872\n",
       "10     9699\n",
       "14     9552\n",
       "9      8933\n",
       "5       860\n",
       "6       363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_Case2['Attack_type'] = label_encoder.fit_transform(df_Case2['Attack_type'])\n",
    "df_Case2['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d78794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befor  (153264, 74)\n",
      "Removed  dns.retransmit_request\n",
      "Removed  mbtcp.len\n",
      "Removed  http.request.method-OPTIONS\n",
      "Removed  http.request.version--a HTTP/1.1\n",
      "Removed  http.request.version-/etc/passwd|?data=Download HTTP/1.1\n",
      "Removed  http.request.version-By Dr HTTP/1.1\n",
      "Removed  dns.qry.name.len-_googlecast._tcp.local\n",
      "After  (153264, 67)\n"
     ]
    }
   ],
   "source": [
    "X = df_Case2.drop(labels=\"Attack_type\",axis=1)\n",
    "Y = df_Case2[\"Attack_type\"]\n",
    "\n",
    "print(\"befor \", X.shape)\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.00001) #0\n",
    "constant_filter.fit(X)\n",
    "constant_columns = [column for column in X.columns\n",
    "                    if column not in\n",
    "X.columns[constant_filter.get_support()]]\n",
    "X2 = constant_filter.transform(X)\n",
    "for column in constant_columns:\n",
    "    print(\"Removed \", column)\n",
    "\n",
    "print(\"After \", X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc19a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122611, 74)\n",
      "(30653, 74)\n",
      "(122611,)\n",
      "(30653,)\n"
     ]
    }
   ],
   "source": [
    "Y_Case2 = df_Case2[\"Attack_type\"]\n",
    "X_Case2 = df_Case2.drop('Attack_type', axis=1) # after filtring feat\n",
    "\n",
    "train_X_case2,test_X_case2,train_Y_case2,test_Y_case2 = train_test_split(X_Case2,Y_Case2,test_size=0.2,random_state=111)\n",
    "print(train_X_case2.shape),\n",
    "print(test_X_case2.shape)\n",
    "print(train_Y_case2.shape)\n",
    "print(test_Y_case2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "104745ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled2, y_train_label_resampled2 = smote.fit_resample(train_X_case2, train_Y_case2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8917b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "0     19291\n",
      "2     19291\n",
      "12    19291\n",
      "9     19291\n",
      "1     19291\n",
      "11    19291\n",
      "4     19291\n",
      "3     19291\n",
      "10    19291\n",
      "14    19291\n",
      "7     19291\n",
      "13    19291\n",
      "8     19291\n",
      "6     19291\n",
      "5     19291\n",
      "Name: count, dtype: int64\n",
      "------------------------------------\n",
      "Attack_type\n",
      "0     19291\n",
      "2     19291\n",
      "12    19291\n",
      "9     19291\n",
      "1     19291\n",
      "11    19291\n",
      "4     19291\n",
      "3     19291\n",
      "10    19291\n",
      "14    19291\n",
      "7     19291\n",
      "13    19291\n",
      "8     19291\n",
      "6     19291\n",
      "5     19291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_label_resampled2.value_counts())\n",
    "print('------------------------------------')\n",
    "print(y_train_label_resampled2.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69e5dd",
   "metadata": {},
   "source": [
    "## 2.1 Testing Models for Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc98e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store training and testing times\n",
    "results_case2 = {\"Model\": [], \"Training Time (s)\": [], \"Testing Time (s)\": [] , \"AUROC\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd05487",
   "metadata": {},
   "source": [
    "### 2.1.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dd16abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9577202883893909\n",
      "AUROC: 0.9730627798427085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a DecisionTreeClassifier instance\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# ---------------------Measure training time---------------------\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "decision_tree.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred = decision_tree.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"DT\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y_case2, y_pred)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "\n",
    "# ------------------ AUROC Calculation --------------------------\n",
    "# Calculate AUROC for multi-class classification using 'ovr' (One-vs-Rest) strategy\n",
    "auroc = roc_auc_score(test_Y_case2, decision_tree.predict_proba(test_X_case2), multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# Optionally, store AUROC\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])  # Ensure key exists\n",
    "results_case2[\"AUROC\"].append(auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e757439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1903\n",
      "           1       0.89      0.89      0.89      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.47      0.88      0.61       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.92      0.95      1793\n",
      "          10       0.96      0.95      0.96      2022\n",
      "          11       0.91      0.90      0.90      2076\n",
      "          12       0.89      0.90      0.90      1939\n",
      "          13       0.97      0.96      0.97      2026\n",
      "          14       0.87      0.88      0.88      1904\n",
      "\n",
      "    accuracy                           0.96     30653\n",
      "   macro avg       0.93      0.95      0.93     30653\n",
      "weighted avg       0.96      0.96      0.96     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487d798",
   "metadata": {},
   "source": [
    "### 2.1.2 RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "572596cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.961537206798682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9958392089428535\n"
     ]
    }
   ],
   "source": [
    "RFC_Model = RandomForestClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "RFC_Model.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_RFC = RFC_Model.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"RFC\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y_case2, y_pred_GS_RFC)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    " \n",
    "# ------------------ AUROC Calculation --------------------------\n",
    "# Calculate AUROC for multi-class classification using 'ovr' (One-vs-Rest) strategy\n",
    "y_probs = RFC_Model.predict_proba(test_X_case2)\n",
    "auroc = roc_auc_score(test_Y_case2, y_probs, multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# store AUROC\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])  # Ensure key exists\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8b5b89d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1903\n",
      "           1       0.91      0.88      0.90      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.63      0.87      0.73       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.96      0.97      1793\n",
      "          10       0.96      0.96      0.96      2022\n",
      "          11       0.89      0.91      0.90      2076\n",
      "          12       0.90      0.88      0.89      1939\n",
      "          13       0.98      0.96      0.97      2026\n",
      "          14       0.86      0.91      0.89      1904\n",
      "\n",
      "    accuracy                           0.96     30653\n",
      "   macro avg       0.94      0.95      0.94     30653\n",
      "weighted avg       0.96      0.96      0.96     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_GS_RFC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e5b0f",
   "metadata": {},
   "source": [
    "### 2.1.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dbc5955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.795279\n",
      "Accuracy: 0.3162822562228819\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model for Multi-Class Classification\n",
    "LR_Model = LogisticRegression(solver='liblinear', multi_class='ovr')  # OvR by default, or 'multinomial' for softmax\n",
    "\n",
    "# --------------------- Measure training time ---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "LR_Model.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_LR = LR_Model.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"Logistic Regression\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_LR = LR_Model.predict_proba(test_X_case2)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "auroc = roc_auc_score(test_Y_case2, y_proba_LR, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y_case2, y_pred_GS_LR)\n",
    "print(\"Accuracy:\", accuracy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "59575f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58      1903\n",
      "           1       0.00      0.00      0.00      2134\n",
      "           2       0.42      0.68      0.52      2843\n",
      "           3       0.59      0.40      0.48      2040\n",
      "           4       0.99      1.00      1.00      2865\n",
      "           5       0.00      0.06      0.00       149\n",
      "           6       0.97      0.95      0.96        78\n",
      "           7       0.97      0.14      0.24      4797\n",
      "           8       0.00      0.00      0.00      2084\n",
      "           9       0.42      0.23      0.30      1793\n",
      "          10       0.00      0.00      0.00      2022\n",
      "          11       0.13      0.19      0.16      2076\n",
      "          12       0.09      0.26      0.13      1939\n",
      "          13       0.17      0.39      0.23      2026\n",
      "          14       0.00      0.00      0.00      1904\n",
      "\n",
      "    accuracy                           0.32     30653\n",
      "   macro avg       0.35      0.33      0.31     30653\n",
      "weighted avg       0.41      0.32      0.30     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_GS_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f4d1e",
   "metadata": {},
   "source": [
    "### 2.1.4 Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5dbd404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9963053885866684\n",
      "Test Accuracy: 0.960362770365054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base model\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "# Define bagging model\n",
    "bagging_model = BaggingClassifier(estimator=base_model)\n",
    "\n",
    "# Train the bagging model\n",
    "bagging_model.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "\n",
    "# Predictions\n",
    "y_pred_bagging = bagging_model.predict(test_X_case2)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Training Accuracy:\", bagging_model.score(train_X_case2, train_Y_case2))\n",
    "print(\"Test Accuracy:\", bagging_model.score(test_X_case2, test_Y_case2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2eef543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1903\n",
      "           1       0.90      0.90      0.90      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.52      0.87      0.65       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.93      0.96      1793\n",
      "          10       0.96      0.95      0.95      2022\n",
      "          11       0.89      0.92      0.91      2076\n",
      "          12       0.91      0.88      0.90      1939\n",
      "          13       0.98      0.96      0.97      2026\n",
      "          14       0.88      0.90      0.89      1904\n",
      "\n",
      "    accuracy                           0.96     30653\n",
      "   macro avg       0.93      0.95      0.94     30653\n",
      "weighted avg       0.96      0.96      0.96     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_Y_case2, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71bb36",
   "metadata": {},
   "source": [
    "### 2.1.5 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1ae90893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9859\n",
      "Classification Report for AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1903\n",
      "           1       0.90      0.89      0.89      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.51      0.89      0.65       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.93      0.96      1793\n",
      "          10       0.96      0.95      0.96      2022\n",
      "          11       0.90      0.90      0.90      2076\n",
      "          12       0.89      0.90      0.90      1939\n",
      "          13       0.97      0.96      0.97      2026\n",
      "          14       0.87      0.89      0.88      1904\n",
      "\n",
      "    accuracy                           0.96     30653\n",
      "   macro avg       0.93      0.95      0.94     30653\n",
      "weighted avg       0.96      0.96      0.96     30653\n",
      "\n",
      "Accuracy: 0.9594\n",
      "Training Time: 145.4196 seconds\n",
      "Testing Time: 0.5342 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Score: 0.9594\n"
     ]
    }
   ],
   "source": [
    "# Create a base classifier (DecisionTreeClassifier is common for AdaBoost)\n",
    "base_estimator = DecisionTreeClassifier()  \n",
    "\n",
    "# Initialize AdaBoost with the base estimator\n",
    "ada_boost = AdaBoostClassifier(estimator=base_estimator)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "ada_boost.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# --------------------- Measure testing time ---------------------\n",
    "start_time = time.time()\n",
    "y_pred_aba = ada_boost.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# --------------------- Evaluate Model ---------------------\n",
    "# Calculate accuracy and other classification metrics\n",
    "accuracy = accuracy_score(test_Y_case2, y_pred_aba)\n",
    "class_report = classification_report(test_Y_case2, y_pred_aba)\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"AdaBoost\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "# --------------------- AUROC Calculation ---------------------\n",
    "# Predict probabilities for AUROC\n",
    "y_proba_aba = ada_boost.predict_proba(test_X_case2)\n",
    "\n",
    "# Determine number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "\n",
    "# Compute AUROC using One-vs-Rest strategy for multiclass\n",
    "auroc = roc_auc_score(test_Y_case2, y_proba_aba, multi_class='ovr')\n",
    "\n",
    "# Print AUROC\n",
    "print(f\"AUROC: {auroc:.4f}\")\n",
    "\n",
    "# Store AUROC in results\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "\n",
    "\n",
    "# Optionally print classification report\n",
    "print(f\"Classification Report for AdaBoost:\\n{class_report}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "print(f\"Testing Time: {testing_time:.4f} seconds\")\n",
    "\n",
    "# --------------------- Final Score ---------------------\n",
    "final_score = ada_boost.score(test_X_case2, test_Y_case2)\n",
    "print(f\"Final Model Score: {final_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ffc8f8",
   "metadata": {},
   "source": [
    "### 2.1.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "725a4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.999313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9694320294914037"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_boost=xgb.XGBClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "xgb_boost.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_xgb = xgb_boost.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"XGBoost\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_xgb = xgb_boost.predict_proba(test_X_case2)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "auroc = roc_auc_score(test_Y_case2, y_proba_xgb, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "\n",
    "xgb_boost.score(test_X_case2,test_Y_case2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a6d73793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1903\n",
      "           1       0.91      0.96      0.93      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.68      0.87      0.77       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.97      0.98      1793\n",
      "          10       0.95      0.97      0.96      2022\n",
      "          11       0.88      0.96      0.92      2076\n",
      "          12       0.96      0.86      0.90      1939\n",
      "          13       1.00      0.96      0.98      2026\n",
      "          14       0.93      0.91      0.92      1904\n",
      "\n",
      "    accuracy                           0.97     30653\n",
      "   macro avg       0.95      0.96      0.95     30653\n",
      "weighted avg       0.97      0.97      0.97     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292f584",
   "metadata": {},
   "source": [
    "### 2.1.7 LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5b4a653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5599\n",
      "[LightGBM] [Info] Number of data points in the train set: 289695, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "AUROC: 0.999275\n",
      "Accuracy: 0.9700192477082178\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1903\n",
      "           1       0.91      0.96      0.93      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.69      0.85      0.76       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.97      0.98      1793\n",
      "          10       0.95      0.97      0.96      2022\n",
      "          11       0.88      0.96      0.92      2076\n",
      "          12       0.96      0.87      0.91      1939\n",
      "          13       0.99      0.96      0.97      2026\n",
      "          14       0.94      0.91      0.92      1904\n",
      "\n",
      "    accuracy                           0.97     30653\n",
      "   macro avg       0.95      0.96      0.95     30653\n",
      "weighted avg       0.97      0.97      0.97     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a new instance of the LGBMClassifier with the best hyperparameters\n",
    "LGBM_Model_best = LGBMClassifier()\n",
    "\n",
    "# --------------------- Measure training time ---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "LGBM_Model_best.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_GS_LGBM = LGBM_Model_best.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"LGBMClassifier\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_LGBM = LGBM_Model_best.predict_proba(test_X_case2)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "auroc = roc_auc_score(test_Y_case2, y_proba_LGBM, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "#------------------------------------------------------------------\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(test_Y_case2, y_pred_GS_LGBM)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "\n",
    "# Optional: Detailed evaluation for multi-class classification\n",
    "print(\"Classification Report:\\n\", classification_report(test_Y_case2, y_pred_GS_LGBM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "bd115698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1903\n",
      "           1       0.91      0.96      0.93      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.69      0.85      0.76       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.97      0.98      1793\n",
      "          10       0.95      0.97      0.96      2022\n",
      "          11       0.88      0.96      0.92      2076\n",
      "          12       0.96      0.87      0.91      1939\n",
      "          13       0.99      0.96      0.97      2026\n",
      "          14       0.94      0.91      0.92      1904\n",
      "\n",
      "    accuracy                           0.97     30653\n",
      "   macro avg       0.95      0.96      0.95     30653\n",
      "weighted avg       0.97      0.97      0.97     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_GS_LGBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc381c2f",
   "metadata": {},
   "source": [
    "### 2.1.8 Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d26cdcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9923126673222296\n",
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994698681194999\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9599386683195772\n"
     ]
    }
   ],
   "source": [
    "ex_tree_clf = ExtraTreesClassifier()\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model to the training data\n",
    "ex_tree_clf.fit( y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# ------------------ AUROC ------------------\n",
    "# Predict probabilities instead of labels\n",
    "proba = ex_tree_clf.predict_proba(test_X_case2)\n",
    "\n",
    "# Get number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "\n",
    "# AUROC calculation\n",
    "auroc = roc_auc_score(test_Y_case2, proba, multi_class='ovr')\n",
    "print(\"AUROC:\", auroc)\n",
    "\n",
    "# ------------------ Store Results ------------------\n",
    "results_case2[\"AUROC\"] = results_case2.get(\"AUROC\", [])\n",
    "results_case2[\"AUROC\"].append(auroc)\n",
    "\n",
    "print (\"Train\")\n",
    "print(accuracy_score(train_Y_case2, ex_tree_clf.predict(train_X_case2)) )\n",
    "print (\"Test\")\n",
    "print( accuracy_score(test_Y_case2.values, ex_tree_clf.predict(test_X_case2)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "701d3094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1903\n",
      "           1       0.90      0.88      0.89      2134\n",
      "           2       1.00      1.00      1.00      2843\n",
      "           3       1.00      1.00      1.00      2040\n",
      "           4       1.00      1.00      1.00      2865\n",
      "           5       0.64      0.89      0.74       149\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00      4797\n",
      "           8       1.00      1.00      1.00      2084\n",
      "           9       0.99      0.96      0.97      1793\n",
      "          10       0.96      0.95      0.96      2022\n",
      "          11       0.90      0.90      0.90      2076\n",
      "          12       0.89      0.89      0.89      1939\n",
      "          13       0.98      0.95      0.97      2026\n",
      "          14       0.86      0.91      0.88      1904\n",
      "\n",
      "    accuracy                           0.96     30653\n",
      "   macro avg       0.94      0.95      0.94     30653\n",
      "weighted avg       0.96      0.96      0.96     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Predict the labels for the test data\n",
    "y_pred_extraTree = ex_tree_clf.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"ExtraTreesClassifier\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_extraTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5441500",
   "metadata": {},
   "source": [
    "### 2.1.9 Stack_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b0a459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.998929\n",
      "Accuracy: 96.77 %\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "ada_boost = AdaBoostClassifier()\n",
    "xgb_boost=xgb.XGBClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# stacking ensemble\n",
    "stack = StackingClassifier( estimators=[\n",
    "                                        ('ada', ada_boost),\n",
    "                                        ('xgb', xgb_boost)],\n",
    "                                        final_estimator= random_forest\n",
    "                                      )\n",
    "\n",
    "\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit ensemble on data\n",
    "stack.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Make predictions\n",
    "y_pred = stack.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"Stacked Ensemble_1\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "# ------------------ AUROC Calculation ------------------\n",
    "# Get probability predictions\n",
    "y_proba_stack_1 = stack.predict_proba(test_X_case2)\n",
    "\n",
    "# Check number of classes\n",
    "n_classes = len(np.unique(test_Y_case2))\n",
    "auroc = roc_auc_score(test_Y_case2, y_proba_stack_1, multi_class='ovr')\n",
    "\n",
    "# Output and store\n",
    "print(f\"AUROC: {auroc:.6f}\")\n",
    "results[\"AUROC\"] = results.get(\"AUROC\", [])\n",
    "results[\"AUROC\"].append(auroc)\n",
    "\n",
    "\n",
    "# Evaluate performance\n",
    "acc = accuracy_score(test_Y_case2, y_pred)\n",
    "acc = acc*100\n",
    "print(f'Accuracy: {acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2077fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      2005\n",
      "           1       0.89      0.95      0.92      2119\n",
      "           2       1.00      1.00      1.00      2880\n",
      "           3       1.00      1.00      1.00      2091\n",
      "           4       1.00      1.00      1.00      2885\n",
      "           5       0.53      0.87      0.66       152\n",
      "           6       1.00      1.00      1.00        69\n",
      "           7       1.00      1.00      1.00      4777\n",
      "           8       1.00      1.00      1.00      1972\n",
      "           9       0.99      0.94      0.96      1781\n",
      "          10       0.95      0.98      0.96      1989\n",
      "          11       0.87      0.98      0.92      2000\n",
      "          12       0.97      0.86      0.91      2040\n",
      "          13       0.99      0.96      0.97      2009\n",
      "          14       0.94      0.90      0.92      1884\n",
      "\n",
      "    accuracy                           0.97     30653\n",
      "   macro avg       0.94      0.96      0.95     30653\n",
      "weighted avg       0.97      0.97      0.97     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack1 = stack.predict(test_X_case2)\n",
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_stack1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ec4e0",
   "metadata": {},
   "source": [
    "### Stack 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8af71a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5599\n",
      "[LightGBM] [Info] Number of data points in the train set: 289995, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5629\n",
      "[LightGBM] [Info] Number of data points in the train set: 231996, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5614\n",
      "[LightGBM] [Info] Number of data points in the train set: 231996, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5555\n",
      "[LightGBM] [Info] Number of data points in the train set: 231996, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5545\n",
      "[LightGBM] [Info] Number of data points in the train set: 231996, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5547\n",
      "[LightGBM] [Info] Number of data points in the train set: 231996, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.72 %\n"
     ]
    }
   ],
   "source": [
    "# Define base models\n",
    "logistic_reg = LogisticRegression()\n",
    "xgb_boost = XGBClassifier()\n",
    "lgbm = LGBMClassifier()\n",
    "extra_trees = ExtraTreesClassifier()\n",
    "\n",
    "# Define the final estimator\n",
    "final_estimator = RandomForestClassifier()\n",
    "\n",
    "# Create a stacking ensemble with a mix of models\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', logistic_reg),\n",
    "        ('xgb', xgb_boost),\n",
    "        ('lgbm', lgbm),\n",
    "        ('extra', extra_trees)\n",
    "    ],\n",
    "    final_estimator=final_estimator\n",
    ")\n",
    "\n",
    "\n",
    "# --------------------- Measure training time---------------------\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit ensemble on data\n",
    "stack.fit(X_train_resampled2.values, y_train_label_resampled2.values)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Measure testing time\n",
    "start_time = time.time()\n",
    "# Make predictions\n",
    "y_pred = stack.predict(test_X_case2)\n",
    "testing_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Store results\n",
    "results_case2[\"Model\"].append(\"Stacked Ensemble_1\")\n",
    "results_case2[\"Training Time (s)\"].append(training_time)\n",
    "results_case2[\"Testing Time (s)\"].append(testing_time)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "# Measure accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_Y_case2, y_pred)\n",
    "print(f'Accuracy: {acc * 100:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8693bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but ExtraTreesClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      2005\n",
      "           1       0.91      0.92      0.92      2119\n",
      "           2       1.00      1.00      1.00      2880\n",
      "           3       1.00      1.00      1.00      2091\n",
      "           4       1.00      1.00      1.00      2885\n",
      "           5       0.62      0.86      0.72       152\n",
      "           6       1.00      1.00      1.00        69\n",
      "           7       1.00      1.00      1.00      4777\n",
      "           8       1.00      1.00      1.00      1972\n",
      "           9       0.99      0.95      0.97      1781\n",
      "          10       0.95      0.97      0.96      1989\n",
      "          11       0.87      0.98      0.92      2000\n",
      "          12       0.97      0.86      0.91      2040\n",
      "          13       0.99      0.96      0.98      2009\n",
      "          14       0.90      0.92      0.91      1884\n",
      "\n",
      "    accuracy                           0.97     30653\n",
      "   macro avg       0.94      0.96      0.95     30653\n",
      "weighted avg       0.97      0.97      0.97     30653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_stack = stack.predict(test_X_case2)\n",
    "print(\"Report :\\n\", classification_report(test_Y_case2, y_pred_stack) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0f75d",
   "metadata": {},
   "source": [
    "# Models Ablation Study :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e40c1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src_host</th>\n",
       "      <th>ip.dst_host</th>\n",
       "      <th>arp.dst.proto_ipv4</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>arp.src.proto_ipv4</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.transmit_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "      <th>mbtcp.trans_id</th>\n",
       "      <th>mbtcp.unit_id</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>192.168.0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>MITM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157795</th>\n",
       "      <td>2021 23:24:32.698981000</td>\n",
       "      <td>193.152.82.43</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>48729.0</td>\n",
       "      <td>40690.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157796</th>\n",
       "      <td>2021 23:24:32.699354000</td>\n",
       "      <td>253.52.1.213</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45657.0</td>\n",
       "      <td>40702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157797</th>\n",
       "      <td>2021 23:24:32.719931000</td>\n",
       "      <td>107.155.221.49</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57686.0</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157798</th>\n",
       "      <td>2021 23:24:32.752054000</td>\n",
       "      <td>77.242.58.228</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9555.0</td>\n",
       "      <td>42379.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157799</th>\n",
       "      <td>2021 23:24:32.780376000</td>\n",
       "      <td>149.40.90.151</td>\n",
       "      <td>192.168.0.128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35144.0</td>\n",
       "      <td>45095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157800 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       frame.time     ip.src_host    ip.dst_host  \\\n",
       "0                             6.0   192.168.0.152            0.0   \n",
       "1                             6.0   192.168.0.101            0.0   \n",
       "2                             6.0   192.168.0.152            0.0   \n",
       "3                             6.0   192.168.0.101            0.0   \n",
       "4                             6.0   192.168.0.152            0.0   \n",
       "...                           ...             ...            ...   \n",
       "157795   2021 23:24:32.698981000    193.152.82.43  192.168.0.128   \n",
       "157796   2021 23:24:32.699354000     253.52.1.213  192.168.0.128   \n",
       "157797   2021 23:24:32.719931000   107.155.221.49  192.168.0.128   \n",
       "157798   2021 23:24:32.752054000    77.242.58.228  192.168.0.128   \n",
       "157799   2021 23:24:32.780376000    149.40.90.151  192.168.0.128   \n",
       "\n",
       "       arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
       "0                     0.0         0.0          0.0                0.0   \n",
       "1                     0.0         0.0          0.0                0.0   \n",
       "2                     0.0         0.0          0.0                0.0   \n",
       "3                     0.0         0.0          0.0                0.0   \n",
       "4                     0.0         0.0          0.0                0.0   \n",
       "...                   ...         ...          ...                ...   \n",
       "157795                  0         0.0          0.0                  0   \n",
       "157796                  0         0.0          0.0                  0   \n",
       "157797                  0         0.0          0.0                  0   \n",
       "157798                  0         0.0          0.0                  0   \n",
       "157799                  0         0.0          0.0                  0   \n",
       "\n",
       "        icmp.checksum  icmp.seq_le  icmp.transmit_timestamp  ...  \\\n",
       "0                 0.0          0.0                      0.0  ...   \n",
       "1                 0.0          0.0                      0.0  ...   \n",
       "2                 0.0          0.0                      0.0  ...   \n",
       "3                 0.0          0.0                      0.0  ...   \n",
       "4                 0.0          0.0                      0.0  ...   \n",
       "...               ...          ...                      ...  ...   \n",
       "157795        48729.0      40690.0                      0.0  ...   \n",
       "157796        45657.0      40702.0                      0.0  ...   \n",
       "157797        57686.0      41423.0                      0.0  ...   \n",
       "157798         9555.0      42379.0                      0.0  ...   \n",
       "157799        35144.0      45095.0                      0.0  ...   \n",
       "\n",
       "        mqtt.proto_len mqtt.protoname  mqtt.topic mqtt.topic_len mqtt.ver  \\\n",
       "0                  0.0            0.0         0.0            0.0      0.0   \n",
       "1                  0.0            0.0         0.0            0.0      0.0   \n",
       "2                  0.0            0.0         0.0            0.0      0.0   \n",
       "3                  0.0            0.0         0.0            0.0      0.0   \n",
       "4                  0.0            0.0         0.0            0.0      0.0   \n",
       "...                ...            ...         ...            ...      ...   \n",
       "157795             0.0            0.0         0.0            0.0      0.0   \n",
       "157796             0.0            0.0         0.0            0.0      0.0   \n",
       "157797             0.0            0.0         0.0            0.0      0.0   \n",
       "157798             0.0            0.0         0.0            0.0      0.0   \n",
       "157799             0.0            0.0         0.0            0.0      0.0   \n",
       "\n",
       "       mbtcp.len mbtcp.trans_id mbtcp.unit_id  Attack_label  Attack_type  \n",
       "0            0.0            0.0           0.0             1         MITM  \n",
       "1            0.0            0.0           0.0             1         MITM  \n",
       "2            0.0            0.0           0.0             1         MITM  \n",
       "3            0.0            0.0           0.0             1         MITM  \n",
       "4            0.0            0.0           0.0             1         MITM  \n",
       "...          ...            ...           ...           ...          ...  \n",
       "157795       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157796       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157797       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157798       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "157799       0.0            0.0           0.0             1    DDoS_ICMP  \n",
       "\n",
       "[157800 rows x 63 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ML-EdgeIIoT-dataset.csv\", low_memory=False) \n",
    "df # pandas.errors.DtypeWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eec1f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame.time            0\n",
      "ip.src_host           0\n",
      "ip.dst_host           0\n",
      "arp.dst.proto_ipv4    0\n",
      "arp.opcode            0\n",
      "                     ..\n",
      "mbtcp.len             0\n",
      "mbtcp.trans_id        0\n",
      "mbtcp.unit_id         0\n",
      "Attack_label          0\n",
      "Attack_type           0\n",
      "Length: 63, dtype: int64\n",
      "----------------------------------------\n",
      "Before removing missing values (157800, 63)\n",
      "After removing missing values (157800, 63)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "copy1 = df.copy(deep=True)\n",
    "print(copy1.isnull().sum())\n",
    "\n",
    "# Drop rows that has missing values\n",
    "print('-'*40)\n",
    "copy2 = df.copy(deep=True)\n",
    "print('Before removing missing values', df.shape)\n",
    "copy2.dropna(inplace=True)\n",
    "print('After removing missing values',copy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5def1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tcp.srcport\"] = df[\"tcp.srcport\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df526594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Backdoor"
          ],
          [
           "DDoS_HTTP"
          ],
          [
           "DDoS_ICMP"
          ],
          [
           "DDoS_TCP"
          ],
          [
           "DDoS_UDP"
          ],
          [
           "Fingerprinting"
          ],
          [
           "MITM"
          ],
          [
           "Normal"
          ],
          [
           "Password"
          ],
          [
           "Port_Scanning"
          ],
          [
           "Ransomware"
          ],
          [
           "SQL_injection"
          ],
          [
           "Uploading"
          ],
          [
           "Vulnerability_scanner"
          ],
          [
           "XSS"
          ]
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hole": 0.3,
         "hovertemplate": "Attack_type=%{customdata[0]}<br>ip.dst_host=%{value}<extra></extra>",
         "labels": [
          "Backdoor",
          "DDoS_HTTP",
          "DDoS_ICMP",
          "DDoS_TCP",
          "DDoS_UDP",
          "Fingerprinting",
          "MITM",
          "Normal",
          "Password",
          "Port_Scanning",
          "Ransomware",
          "SQL_injection",
          "Uploading",
          "Vulnerability_scanner",
          "XSS"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "textinfo": "percent+label",
         "textposition": "inside",
         "type": "pie",
         "values": {
          "bdata": "0ydBKQo3ByiiOOkDvgTtXgUnVyetKkcoHShcJ0Qn",
          "dtype": "i2"
         }
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Total Number of Attack baced on Type"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.pie(Attack,\n",
    "             values=\"ip.dst_host\",\n",
    "             names='Attack_type',\n",
    "             title='Total Number of Attack baced on Type',\n",
    "             hover_data=['Attack_type'], \n",
    "             hole=0.3,\n",
    "            )\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca4c3859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>quantile</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.998420e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60076.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.318491e+06</td>\n",
       "      <td>1309285.5</td>\n",
       "      <td>1309285.5</td>\n",
       "      <td>2898725.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attack_label          mean     median   quantile        max   min\n",
       "0             0  1.998420e+01        0.0        0.0    60076.0   0.0\n",
       "1             1  1.318491e+06  1309285.5  1309285.5  2898725.0  12.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['Attack_type'].isin(['Normal', 'DDoS_UDP'])]\n",
    "selected_columns = filtered_df[['dns.qry.name', 'icmp.seq_le', 'udp.stream', 'Attack_label']]\n",
    "summary_stats = selected_columns.groupby('Attack_label')['udp.stream'].agg(['mean', 'median', 'quantile', 'max', 'min']).reset_index()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e04a2c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214     2021-01-01 22:14:30.939803\n",
      "1215     2021-01-01 22:14:30.939896\n",
      "1216     2021-01-01 22:14:31.371846\n",
      "1217     2021-01-01 22:14:31.371927\n",
      "1218     2021-01-01 22:14:31.910480\n",
      "                    ...            \n",
      "157795   2021-01-01 23:24:32.698981\n",
      "157796   2021-01-01 23:24:32.699354\n",
      "157797   2021-01-01 23:24:32.719931\n",
      "157798   2021-01-01 23:24:32.752054\n",
      "157799   2021-01-01 23:24:32.780376\n",
      "Name: frame.time, Length: 142095, dtype: datetime64[ns]\n",
      "------------------------------------------------\n",
      "Before removing missing values (157800, 63)\n",
      "After removing missing values (142095, 63)\n"
     ]
    }
   ],
   "source": [
    "copy1 = df.copy(deep=True)\n",
    "\n",
    "# Drop rows with values of '6.0' or '0.0' in the 'frame.time' column\n",
    "copy1 = copy1[~copy1['frame.time'].isin([6.0, 0.0])]\n",
    "\n",
    "# Convert 'frame.time' column to datetime data type\n",
    "copy1['frame.time'] = pd.to_datetime(copy1['frame.time'], errors='coerce')\n",
    "copy1 = copy1.dropna(subset=['frame.time'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(copy1['frame.time'])\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('Before removing missing values', df.shape)\n",
    "print('After removing missing values',copy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc605f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting IP add\n",
    "def ip_to_int(ip):\n",
    "    try:\n",
    "        return int(ipaddress.IPv4Address(ip))\n",
    "    except ipaddress.AddressValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ef9397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  0\n",
      "1                  0\n",
      "2                  0\n",
      "3                  0\n",
      "4                  0\n",
      "             ...    \n",
      "157795    3232235648\n",
      "157796    3232235648\n",
      "157797    3232235648\n",
      "157798    3232235648\n",
      "157799    3232235648\n",
      "Name: ip.dst_host, Length: 157800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"ip.dst_host\"] = df[\"ip.dst_host\"].apply(ip_to_int)\n",
    "print(df[\"ip.dst_host\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74512b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ip.dst_host\"] = df[\"ip.dst_host\"].apply(ip_to_int)\n",
    "df['ip.src_host'] = df['ip.src_host'].apply(ip_to_int)\n",
    "#Col arp.dst.proto_ipv4\n",
    "df['arp.dst.proto_ipv4'] = df['arp.dst.proto_ipv4'].apply(ip_to_int)\n",
    "#Col arp.src.proto_ipv4\n",
    "df['arp.src.proto_ipv4'] = df['arp.src.proto_ipv4'].apply(ip_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf62c785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "157795    0.0\n",
       "157796    0.0\n",
       "157797    0.0\n",
       "157798    0.0\n",
       "157799    0.0\n",
       "Name: http.file_data, Length: 157800, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract text content from HTML\n",
    "def extract_text(html):\n",
    "    if pd.isnull(html) or not isinstance(html, str):\n",
    "        return ''  # Return an empty string for missing or non-string values\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "# Remove HTML tags and extract text content\n",
    "df['text_content'] = df['http.file_data'].apply(extract_text)\n",
    "# Extract numerical features\n",
    "df['text_length'] = df['text_content'].apply(len)\n",
    "df['word_count'] = df['text_content'].apply(lambda x: len(x.split()))\n",
    "# Add more feature extraction steps as needed\n",
    "\n",
    "# Convert columns to numerical data type\n",
    "numerical_features = ['text_length', 'word_count']  # Add more feature names if needed\n",
    "df[numerical_features] = df[numerical_features].astype(float)\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Print the preprocessed col\n",
    "df['http.file_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97146252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "Normal                   24110\n",
      "DDoS_UDP                 14498\n",
      "DDoS_ICMP                14090\n",
      "DDoS_HTTP                10495\n",
      "SQL_injection            10285\n",
      "DDoS_TCP                 10247\n",
      "Uploading                10222\n",
      "Vulnerability_scanner    10064\n",
      "Password                  9974\n",
      "Backdoor                  9872\n",
      "Ransomware                9699\n",
      "XSS                       9552\n",
      "Port_Scanning             8933\n",
      "Fingerprinting             860\n",
      "MITM                       363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['frame.time','http.file_data',\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "                \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "                \"tcp.dstport\", \"udp.port\", \"mqtt.msg\", \"icmp.unused\", \"http.tls_port\",\n",
    "                'dns.qry.type', 'dns.retransmit_request_in', \"mqtt.msg_decoded_as\",\n",
    "                \"mbtcp.trans_id\", \"mbtcp.unit_id\", 'text_content']\n",
    "\n",
    "df.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbba8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_dummy(df, name):\n",
    "\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "\n",
    "    for x in dummies.columns:\n",
    "\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "\n",
    "        df[dummy_name] = dummies[x]\n",
    "\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "encode_text_dummy(df,'http.request.method')\n",
    "encode_text_dummy(df,'http.referer')\n",
    "encode_text_dummy(df,\"http.request.version\")\n",
    "encode_text_dummy(df,\"dns.qry.name.len\")\n",
    "encode_text_dummy(df,\"mqtt.conack.flags\")\n",
    "encode_text_dummy(df,\"mqtt.protoname\")\n",
    "encode_text_dummy(df,\"mqtt.topic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c40ce849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "7     24110\n",
       "4     14498\n",
       "2     14090\n",
       "1     10495\n",
       "11    10285\n",
       "3     10247\n",
       "12    10222\n",
       "13    10064\n",
       "8      9974\n",
       "0      9872\n",
       "10     9699\n",
       "14     9552\n",
       "9      8933\n",
       "5       860\n",
       "6       363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Attack_type'] = label_encoder.fit_transform(df['Attack_type'])\n",
    "df['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "733e4688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befor  (153264, 74)\n",
      "Removed  dns.retransmit_request\n",
      "Removed  mbtcp.len\n",
      "Removed  http.request.method-OPTIONS\n",
      "Removed  http.request.version--a HTTP/1.1\n",
      "Removed  http.request.version-/etc/passwd|?data=Download HTTP/1.1\n",
      "Removed  http.request.version-By Dr HTTP/1.1\n",
      "Removed  dns.qry.name.len-_googlecast._tcp.local\n",
      "After  (153264, 67)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(labels=\"Attack_type\",axis=1)\n",
    "Y = df[\"Attack_type\"]\n",
    "\n",
    "print(\"befor \", X.shape)\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0.00001) #0\n",
    "constant_filter.fit(X)\n",
    "constant_columns = [column for column in X.columns\n",
    "                    if column not in\n",
    "X.columns[constant_filter.get_support()]]\n",
    "X2 = constant_filter.transform(X)\n",
    "for column in constant_columns:\n",
    "    print(\"Removed \", column)\n",
    "\n",
    "print(\"After \", X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8c03fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122611, 67)\n",
      "(30653, 67)\n",
      "(122611,)\n",
      "(30653,)\n"
     ]
    }
   ],
   "source": [
    "X = X2 # after filtring feat\n",
    "Y = df[\"Attack_type\"]\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2,random_state=111)\n",
    "print(train_X.shape),\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9d4d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled2, y_train_label_resampled2 = smote.fit_resample(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "563c7ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type\n",
      "7     19318\n",
      "4     11585\n",
      "2     11319\n",
      "1      8383\n",
      "11     8217\n",
      "12     8153\n",
      "3      8086\n",
      "8      8071\n",
      "13     8056\n",
      "0      7915\n",
      "10     7747\n",
      "14     7602\n",
      "9      7175\n",
      "5       693\n",
      "6       291\n",
      "Name: count, dtype: int64\n",
      "------------------------------------\n",
      "Attack_type\n",
      "7     19318\n",
      "3     19318\n",
      "11    19318\n",
      "10    19318\n",
      "2     19318\n",
      "9     19318\n",
      "1     19318\n",
      "0     19318\n",
      "8     19318\n",
      "14    19318\n",
      "13    19318\n",
      "4     19318\n",
      "12    19318\n",
      "5     19318\n",
      "6     19318\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.value_counts())\n",
    "print('------------------------------------')\n",
    "print(y_train_label_resampled2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa3d01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"Model\": [], \"Training Time (s)\": [], \"Testing Time (s)\": [] , \"AUROC\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f364715",
   "metadata": {},
   "source": [
    "## 2.1 Stacked Ensemble_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d4c8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simplified ablation\n",
      "Full_Stacked_Ensemble               | Acc = 0.9592 | Prec = 0.9606 | Rec = 0.9592 | F1 = 0.9593 | Time = 140.38s\n",
      "Without_MetaLearner (Avg Ada+XGB)   | Acc = 0.9550 | Prec = 0.9603 | Rec = 0.9550 | F1 = 0.9547 | Time = 29.01s\n",
      "Without_AdaBoost                    | Acc = 0.9585 | Prec = 0.9599 | Rec = 0.9585 | F1 = 0.9586 | Time = 67.73s\n",
      "Without_XGBoost                     | Acc = 0.4725 | Prec = 0.3796 | Rec = 0.4725 | F1 = 0.4013 | Time = 83.15s\n",
      "\n",
      "===== Simplified Ablation Summary =====\n",
      "\n",
      "Full_Stacked_Ensemble\n",
      "  Accuracy  : 0.9592\n",
      "  Precision : 0.9606\n",
      "  Recall    : 0.9592\n",
      "  F1        : 0.9593\n",
      "  Time (s)  : 140.3775\n",
      "\n",
      "Without_MetaLearner (Avg Ada+XGB)\n",
      "  Accuracy  : 0.9550\n",
      "  Precision : 0.9603\n",
      "  Recall    : 0.9550\n",
      "  F1        : 0.9547\n",
      "  Time (s)  : 29.0089\n",
      "\n",
      "Without_AdaBoost\n",
      "  Accuracy  : 0.9585\n",
      "  Precision : 0.9599\n",
      "  Recall    : 0.9585\n",
      "  F1        : 0.9586\n",
      "  Time (s)  : 67.7252\n",
      "\n",
      "Without_XGBoost\n",
      "  Accuracy  : 0.4725\n",
      "  Precision : 0.3796\n",
      "  Recall    : 0.4725\n",
      "  F1        : 0.4013\n",
      "  Time (s)  : 83.1526\n"
     ]
    }
   ],
   "source": [
    "#  Base and Meta Models\n",
    "\n",
    "ada_boost = AdaBoostClassifier(random_state=1)\n",
    "xgb_boost = XGBClassifier(random_state=1, learning_rate=0.01, eval_metric='logloss', use_label_encoder=False)\n",
    "random_forest = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "\n",
    "# Full Stacked Ensemble\n",
    "\n",
    "Stacked_Ensemble_1 = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('ada', ada_boost),\n",
    "        ('xgb', xgb_boost)\n",
    "    ],\n",
    "    final_estimator=random_forest,\n",
    "    cv=5,\n",
    "    passthrough=False,\n",
    "    stack_method='predict_proba'\n",
    ")\n",
    "\n",
    "\n",
    "#  Focused Ablation Scenarios\n",
    "\n",
    "ablation_scenarios = {\n",
    "    \"Full_Stacked_Ensemble\": Stacked_Ensemble_1,\n",
    "    \"Without_MetaLearner (Avg Ada+XGB)\": None,  # handled manually\n",
    "    \"Without_AdaBoost\": StackingClassifier(\n",
    "        estimators=[('xgb', xgb_boost)],\n",
    "        final_estimator=random_forest,\n",
    "        cv=5,\n",
    "        stack_method='predict_proba',\n",
    "        passthrough=False\n",
    "    ),\n",
    "    \"Without_XGBoost\": StackingClassifier(\n",
    "        estimators=[('ada', ada_boost)],\n",
    "        final_estimator=random_forest,\n",
    "        cv=5,\n",
    "        stack_method='predict_proba',\n",
    "        passthrough=False\n",
    "    )\n",
    "}\n",
    "\n",
    "# Run Ablation \n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Running simplified ablation\")\n",
    "\n",
    "for name, model in ablation_scenarios.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Case 1: Normal Stacking Model ---\n",
    "    if model is not None:\n",
    "        mdl = clone(model)\n",
    "        mdl.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        y_pred = mdl.predict(test_X)\n",
    "    \n",
    "    # --- Case 2: Without Meta-Learner (average base model predictions) ---\n",
    "    else:\n",
    "        ada = clone(ada_boost)\n",
    "        xgb = clone(xgb_boost)\n",
    "        ada.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        xgb.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        avg_proba = (ada.predict_proba(test_X) + xgb.predict_proba(test_X)) / 2\n",
    "        y_pred = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(test_Y, y_pred)\n",
    "    prec = precision_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"Time (s)\": elapsed\n",
    "    }\n",
    "\n",
    "    print(f\"{name:35s} | Acc = {acc:.4f} | Prec = {prec:.4f} | \"\n",
    "          f\"Rec = {rec:.4f} | F1 = {f1:.4f} | Time = {elapsed:.2f}s\")\n",
    "\n",
    "\n",
    "# Summary\n",
    "\n",
    "print(\"\\n===== Simplified Ablation Summary =====\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:10s}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd664f",
   "metadata": {},
   "source": [
    "## 2.2 Stacked Ensemble_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b9030dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simplified ablation\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7672\n",
      "[LightGBM] [Info] Number of data points in the train set: 289770, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "Without_MetaLearner (Avg LR+XGB+LGBM+ETC) | Acc = 0.9647 | Prec = 0.9652 | Rec = 0.9647 | F1 = 0.9648 | Time = 154.23s\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7672\n",
      "[LightGBM] [Info] Number of data points in the train set: 289770, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7777\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7766\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7629\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7618\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7592\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "Without_LogisticRegression          | Acc = 0.9648 | Prec = 0.9662 | Rec = 0.9648 | F1 = 0.9651 | Time = 439.68s\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7672\n",
      "[LightGBM] [Info] Number of data points in the train set: 289770, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7777\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7766\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7629\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7618\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7592\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "Without_XGBoost                     | Acc = 0.9652 | Prec = 0.9662 | Rec = 0.9652 | F1 = 0.9653 | Time = 838.19s\n",
      "Without_LGBM                        | Acc = 0.9629 | Prec = 0.9639 | Rec = 0.9629 | F1 = 0.9632 | Time = 748.40s\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7672\n",
      "[LightGBM] [Info] Number of data points in the train set: 289770, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7777\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7766\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7629\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7618\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7592\n",
      "[LightGBM] [Info] Number of data points in the train set: 231816, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708011\n",
      "[LightGBM] [Info] Start training from score -2.708076\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "[LightGBM] [Warning] Unknown parameter: solver\n",
      "Without_ExtraTrees                  | Acc = 0.9670 | Prec = 0.9683 | Rec = 0.9670 | F1 = 0.9671 | Time = 781.55s\n",
      "\n",
      "===== Simplified Ablation Summary =====\n",
      "\n",
      "Without_MetaLearner (Avg LR+XGB+LGBM+ETC)\n",
      "  Accuracy  : 0.9647\n",
      "  Precision : 0.9652\n",
      "  Recall    : 0.9647\n",
      "  F1        : 0.9648\n",
      "  Time (s)  : 154.2311\n",
      "\n",
      "Without_LogisticRegression\n",
      "  Accuracy  : 0.9648\n",
      "  Precision : 0.9662\n",
      "  Recall    : 0.9648\n",
      "  F1        : 0.9651\n",
      "  Time (s)  : 439.6778\n",
      "\n",
      "Without_XGBoost\n",
      "  Accuracy  : 0.9652\n",
      "  Precision : 0.9662\n",
      "  Recall    : 0.9652\n",
      "  F1        : 0.9653\n",
      "  Time (s)  : 838.1937\n",
      "\n",
      "Without_LGBM\n",
      "  Accuracy  : 0.9629\n",
      "  Precision : 0.9639\n",
      "  Recall    : 0.9629\n",
      "  F1        : 0.9632\n",
      "  Time (s)  : 748.4000\n",
      "\n",
      "Without_ExtraTrees\n",
      "  Accuracy  : 0.9670\n",
      "  Precision : 0.9683\n",
      "  Recall    : 0.9670\n",
      "  F1        : 0.9671\n",
      "  Time (s)  : 781.5460\n"
     ]
    }
   ],
   "source": [
    "# base models\n",
    "Logistic_Reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "XGBoost = XGBClassifier(random_state=42, learning_rate=0.01)\n",
    "LGBM = LGBMClassifier(n_estimators=100, random_state=42 , solver='saga')\n",
    "Extra_Trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "# Define the final estimator\n",
    "Final_Estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "#  Full Stacked Ensemble\n",
    "\n",
    "Stacked_Ensemble_2 = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('logreg', Logistic_Reg),\n",
    "        ('xgb', XGBoost),\n",
    "        ('lgbm', LGBM),\n",
    "        ('et', Extra_Trees)\n",
    "    ],\n",
    "    final_estimator=Final_Estimator,\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Define Focused Ablation Scenarios\n",
    "\n",
    "\n",
    "\n",
    "ablation_scenarios = {\n",
    "#    \"Full_Stacked_Ensemble_2\": Stacked_Ensemble_2,\n",
    "    \n",
    "    \"Without_MetaLearner (Avg LR+XGB+LGBM+ETC)\": None,  # handled manually\n",
    "    \n",
    "    \"Without_LogisticRegression\": StackingClassifier(\n",
    "        estimators=[('xgb', XGBoost),\n",
    "                    ('lgbm', LGBM),\n",
    "                    ('et', Extra_Trees)],\n",
    "        final_estimator=Final_Estimator,\n",
    "        cv=5, stack_method='predict_proba',\n",
    "        passthrough=False),\n",
    "    \n",
    "    \"Without_XGBoost\": StackingClassifier(\n",
    "        estimators=[('logreg', Logistic_Reg),\n",
    "                    ('lgbm', LGBM),\n",
    "                    ('et', Extra_Trees)],\n",
    "        final_estimator=Final_Estimator,\n",
    "        cv=5, stack_method='predict_proba',\n",
    "        passthrough=False),\n",
    "\n",
    "    \"Without_LGBM\": StackingClassifier(\n",
    "        estimators=[('logreg', Logistic_Reg),\n",
    "                    ('xgb', XGBoost),\n",
    "                    ('et', Extra_Trees)],\n",
    "        final_estimator=Final_Estimator,\n",
    "        cv=5, stack_method='predict_proba',\n",
    "        passthrough=False),\n",
    "    \n",
    "    \"Without_ExtraTrees\": StackingClassifier(\n",
    "        estimators=[('logreg', Logistic_Reg),\n",
    "                    ('xgb', XGBoost),\n",
    "                    ('lgbm', LGBM)],\n",
    "        final_estimator=Final_Estimator,\n",
    "        cv=5, stack_method='predict_proba',\n",
    "        passthrough=False),\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Run Ablation (Single Train-Test Split)\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Running simplified ablation\")\n",
    "\n",
    "for name, model in ablation_scenarios.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Case 1: Normal Stacking Model ---\n",
    "    if model is not None:\n",
    "        mdl = clone(model)\n",
    "        mdl.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        y_pred = mdl.predict(test_X)\n",
    "    \n",
    "    # --- Case 2: Without Meta-Learner (average base model predictions) ---\n",
    "    else:\n",
    "        Logistic_Reg = clone(Logistic_Reg)\n",
    "        XGBoost = clone(XGBoost)\n",
    "        LGBM = clone(LGBM)\n",
    "        Extra_Trees = clone(Extra_Trees)\n",
    "        \n",
    "        \n",
    "        Logistic_Reg.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        XGBoost.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        LGBM.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        Extra_Trees.fit(X_train_resampled2, y_train_label_resampled2)\n",
    "        \n",
    "        \n",
    "        avg_proba = (Logistic_Reg.predict_proba(test_X) + XGBoost.predict_proba(test_X) + LGBM.predict_proba(test_X) + Extra_Trees.predict_proba(test_X)) / 4\n",
    "        y_pred = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(test_Y, y_pred)\n",
    "    prec = precision_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(test_Y, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"Time (s)\": elapsed\n",
    "    }\n",
    "\n",
    "    print(f\"{name:35s} | Acc = {acc:.4f} | Prec = {prec:.4f} | \"\n",
    "          f\"Rec = {rec:.4f} | F1 = {f1:.4f} | Time = {elapsed:.2f}s\")\n",
    "\n",
    "# Summary\n",
    "\n",
    "print(\"\\n===== Simplified Ablation Summary =====\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:10s}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f93bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
